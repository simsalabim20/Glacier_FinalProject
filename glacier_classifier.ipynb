{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv'\n",
    "glathida_rgis = pd.read_csv(data_name, low_memory=False)\n",
    "glathida_rgis = glathida_rgis.dropna()\n",
    "df = glathida_rgis.drop(columns = 'RGIId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Land-terminating :  3037074\n",
      "1 Marine-terminating :  611040\n",
      "2 Lake-terminating :  24396\n",
      "3 Dry calving :  0\n",
      "4 Regenerated :  0\n",
      "5 Shelf-terminating :  227601\n",
      "6 Not assigned :  0\n"
     ]
    }
   ],
   "source": [
    "glacierTermTypes = ('Land-terminating', 'Marine-terminating', 'Lake-terminating',\n",
    "                     'Dry calving', 'Regenerated', 'Shelf-terminating', 'Not assigned')\n",
    "glacierID = (0, 1, 2, 3, 4, 5, 9)\n",
    "\n",
    "for i in range(len(glacierTermTypes)):\n",
    "    print(i, glacierTermTypes[i],': ', np.size(df[df['TermType'] == glacierID[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only four of the TermTypes exists. Why are the other included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_size, target):\n",
    "    # Initial data split into x and y values.\n",
    "    xData = pd.DataFrame(data)\n",
    "    xData = xData.drop(columns = [target])\n",
    "    # Target\n",
    "    yData = data[target]\n",
    "\n",
    "    # Split into test and training data\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(xData, yData, test_size = test_size, random_state = 42)\n",
    "\n",
    "    return xTrain, xTest, yTrain, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = split(df, 0.2, 'TermType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron (MLP)\n",
    "def ClassMLP_crude(xTrain, xTest, yTrain, yTest):\n",
    "    # Define and train MLP classifier\n",
    "    ClassifierMLP = MLPClassifier(random_state = 42, early_stopping=True)\n",
    "    \n",
    "    # Train the model on training data\n",
    "    ClassifierMLP.fit(xTrain, yTrain)\n",
    "\n",
    "    # Compute predictions from trained model:\n",
    "    pre = ClassifierMLP.predict(xTest)\n",
    "    acc = accuracy_score(yTest, pre)\n",
    "    \n",
    "    return acc, pre    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.9364998173182316\n",
      "\n",
      "Clasification prediction:\n",
      "0 Land-terminating 10810\n",
      "1 Marine-terminating 2082\n",
      "2 Lake-terminating 17\n",
      "3 Dry calving 0\n",
      "4 Regenerated 0\n",
      "5 Shelf-terminating 776\n",
      "6 Not assigned 0\n"
     ]
    }
   ],
   "source": [
    "acc, pre = ClassMLP_crude(xTrain, xTest, yTrain, yTest)\n",
    "\n",
    "print('Accuracy:')\n",
    "print(acc)\n",
    "print()\n",
    "print('Clasification prediction:')\n",
    "for i in range(len(glacierTermTypes)):\n",
    "    print(i, glacierTermTypes[i], len(pre[np.where(pre == i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter optimization with grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated hidden layer neurons: 152, 114 and 91\n"
     ]
    }
   ],
   "source": [
    "# Number of output neurons, Number of input neurons, Number of samples in training set, scaling factor in range 2-10.\n",
    "def hiddenLayerSize(No, Ni, Ns, alpha): # Tries to estimate optimal hidden layer neurons.\n",
    "    Nh = Ns / (alpha * (Ni + No))\n",
    "    return Nh\n",
    "\n",
    "Nh1 = int(hiddenLayerSize(4, np.shape(xTrain)[1], np.shape(xTrain)[0], 6))\n",
    "Nh2 = int(hiddenLayerSize(4, np.shape(xTrain)[1], np.shape(xTrain)[0], 8))\n",
    "Nh3 = int(hiddenLayerSize(4, np.shape(xTrain)[1], np.shape(xTrain)[0], 10))\n",
    "print(f'Estimated hidden layer neurons: {Nh1}, {Nh2} and {Nh3}')\n",
    "\n",
    "hParamGrid = {'activation': ['relu', 'tanh'],\n",
    "               'alpha': [0.0001, 0.001, 0.01],\n",
    "               'solver': ['adam', 'sgd'],\n",
    "               'early_stopping': [True],\n",
    "               'learning_rate': ['constant', 'adaptive'],\n",
    "               'hidden_layer_sizes': [(Nh1, Nh1, int(Nh1 / 3)),\n",
    "                                      (Nh2, Nh2, int(Nh2 / 3)), \n",
    "                                      (Nh3, Nh3, int(Nh3 / 3))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassMLPgrid(xTrain, xTest, yTrain, yTest, paramSpace, maxIts, crossValids):\n",
    "    # Define the MLPClassifier.\n",
    "    mlp = MLPClassifier(max_iter = maxIts, random_state = 42)\n",
    "\n",
    "    print(\"Data normalizing.\")\n",
    "    scaler = StandardScaler()\n",
    "    xTrain = scaler.fit_transform(xTrain)\n",
    "    xTest = scaler.transform(xTest)\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    print(\"Grid search hyperparameter optimization.\")\n",
    "    grid_search = GridSearchCV(estimator = mlp, param_grid = paramSpace, cv = crossValids, n_jobs = -1)\n",
    "    grid_search.fit(xTrain, yTrain)\n",
    "\n",
    "    # Best parameters found during grid search.\n",
    "    print(\"Best hyperparameters found:\")\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train MLPRegressor with best parameters.\n",
    "    print(\"Training optimized model\")\n",
    "    best_mlp = MLPClassifier(max_iter = maxIts, **best_params)\n",
    "    best_mlp.fit(xTrain, yTrain)\n",
    "\n",
    "    print(\"Finished model\")\n",
    "    pre = best_mlp.predict(xTest)\n",
    "    acc = best_mlp.accuracy_score(yTest, pre)\n",
    "\n",
    "    return best_mlp, best_params, acc, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalizing.\n",
      "Grid search hyperparameter optimization.\n"
     ]
    }
   ],
   "source": [
    "bestMLP, bestParams, acc, pre = ClassMLPgrid(xTrain, xTest, yTrain, yTest,hParamGrid, 20, 5)\n",
    "\n",
    "print('Accuracy:')\n",
    "print(acc)\n",
    "print()\n",
    "print(f'Best hyperparameters: {bestParams}')\n",
    "print()\n",
    "print('Clasification prediction:')\n",
    "for i in range(len(glacierTermTypes)):\n",
    "    print(i, glacierTermTypes[i], len(pre[np.where(pre == i)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer neuron range estimation: 91 and 152\n"
     ]
    }
   ],
   "source": [
    "NhMax = int(hiddenLayerSize(4, np.shape(xTrain)[1], np.shape(xTrain)[0], 6))\n",
    "NhMin = int(hiddenLayerSize(4, np.shape(xTrain)[1], np.shape(xTrain)[0], 10))\n",
    "print(f'Hidden layer neuron range estimation: {NhMin} and {NhMax}')\n",
    "\n",
    "hParamSpace = {'activation': ['relu', 'tanh'],\n",
    "               'alpha': uniform(0.001, 0.1),\n",
    "               'solver': ['adam', 'sgd'],\n",
    "               'early_stopping': [True],\n",
    "               'learning_rate': ['constant', 'adaptive'],\n",
    "               'hidden_layer_sizes': [(randint(NhMin, NhMax).rvs(),\n",
    "                                       randint(NhMin, NhMax).rvs(), \n",
    "                                       int(0.3 * randint(NhMin, NhMax).rvs()))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassMLPran(xTrain, xTest, yTrain, yTest, paramSpace, maxIts, crossValids):\n",
    "    # Define the MLPClassifier.\n",
    "    mlp = MLPClassifier(max_iter = maxIts, random_state = 42)\n",
    "\n",
    "    print(\"Data normalizing.\")\n",
    "    scaler = StandardScaler()\n",
    "    xTrain = scaler.fit_transform(xTrain)\n",
    "    xTest = scaler.transform(xTest)\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    print(\"Grid search hyperparameter optimization.\")\n",
    "    grid_search = RandomizedSearchCV(estimator = mlp, param_distributions = paramSpace, cv = crossValids, n_jobs = -1)\n",
    "    grid_search.fit(xTrain, yTrain)\n",
    "\n",
    "    # Best parameters found during grid search.\n",
    "    print(\"Best hyperparameters found:\")\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)\n",
    "\n",
    "    # Train MLPRegressor with best parameters.\n",
    "    print(\"Training optimized model\")\n",
    "    best_mlp = MLPClassifier(max_iter = maxIts, **best_params)\n",
    "    best_mlp.fit(xTrain, yTrain)\n",
    "\n",
    "    print(\"Finished model\")\n",
    "    pre = best_mlp.predict(xTest)\n",
    "    acc = best_mlp.accuracy_score(yTest, pre)\n",
    "\n",
    "    return best_mlp, best_params, acc, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalizing.\n",
      "Grid search hyperparameter optimization.\n"
     ]
    }
   ],
   "source": [
    "bestMLP, bestParams, acc, pre = ClassMLPran(xTrain, xTest, yTrain, yTest, hParamSpace, 20, 5)\n",
    "\n",
    "print('Accuracy:')\n",
    "print(acc)\n",
    "print()\n",
    "print(f'Best hyperparameters: {bestParams}')\n",
    "print()\n",
    "print('Clasification prediction:')\n",
    "for i in range(len(glacierTermTypes)):\n",
    "    print(i, glacierTermTypes[i], len(pre[np.where(pre == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
