{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96890011-0d5e-4b6b-860e-3898c2e0ce7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import oggm\n",
    "from oggm import utils\n",
    "\n",
    "from __future__ import print_function, division   # Ensures Python3 printing & division standard\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,mean_squared_error, mean_absolute_error, r2_score, roc_curve,auc\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,export_graphviz\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from scipy.stats import randint, poisson\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "\n",
    "import csv\n",
    "\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3ef305a2-c83d-4e6b-9664-50d4701d6bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68423, 72)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# metadata_file = \"metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "# glathida_rgis = pd.read_csv(metadata_file, low_memory=False)\n",
    "# df3 = glathida_rgis.drop(glathida_rgis[glathida_rgis['THICKNESS'] < 0.5].index)\n",
    "\n",
    "# print(np.shape(df3))\n",
    "\n",
    "metadata_file = \"no_zeros_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "glathida_rgis = pd.read_csv(metadata_file, low_memory=False)\n",
    "glathida_rgis = glathida_rgis.dropna()\n",
    "# # glathida_rgis['lat'] = glathida_rgis['POINT_LAT']\n",
    "glathida_rgis['v50'] = np.sqrt(glathida_rgis['vx_gf50']**2 + glathida_rgis['vy_gf50']**2)\n",
    "glathida_rgis['v100'] = np.sqrt(glathida_rgis['vx_gf100']**2 + glathida_rgis['vy_gf100']**2)\n",
    "glathida_rgis['v150'] = np.sqrt(glathida_rgis['vx_gf150']**2 + glathida_rgis['vy_gf150']**2)\n",
    "glathida_rgis['v300'] = np.sqrt(glathida_rgis['vx_gf300']**2 + glathida_rgis['vy_gf300']**2)\n",
    "glathida_rgis['v450'] = np.sqrt(glathida_rgis['vx_gf450']**2 + glathida_rgis['vy_gf450']**2)\n",
    "glathida_rgis['vgfa'] = np.sqrt(glathida_rgis['vx_gfa']**2 + glathida_rgis['vy_gfa']**2)\n",
    "glathida_rgis['dvx'] = np.sqrt(glathida_rgis['dvx_dx']**2 + glathida_rgis['dvx_dy']**2)\n",
    "\n",
    "glathida_rgis['slope50'] = np.sqrt(glathida_rgis['slope_lon_gf50']**2 + glathida_rgis['slope_lat_gf50']**2)\n",
    "glathida_rgis['slope100'] = np.sqrt(glathida_rgis['slope_lon_gf100']**2 + glathida_rgis['slope_lat_gf100']**2)\n",
    "glathida_rgis['slope150'] = np.sqrt(glathida_rgis['slope_lon_gf150']**2 + glathida_rgis['slope_lat_gf150']**2)\n",
    "glathida_rgis['slope300'] = np.sqrt(glathida_rgis['slope_lon_gf300']**2 + glathida_rgis['slope_lat_gf300']**2)\n",
    "glathida_rgis['slope450'] = np.sqrt(glathida_rgis['slope_lon_gf450']**2 + glathida_rgis['slope_lat_gf450']**2)\n",
    "glathida_rgis['slopegfa'] = np.sqrt(glathida_rgis['slope_lon_gfa']**2 + glathida_rgis['slope_lat_gfa']**2)\n",
    "# glathida_rgis['elevation_from_zmin'] = glathida_rgis['elevation'] - glathida_rgis['Zmin']\n",
    "\n",
    "print(np.shape(glathida_rgis))\n",
    "\n",
    "# Group by 'RGIId' and get the unique 'Form' value for each 'RGIId'\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "# Function to convert 'Form' value to 2D vector\n",
    "def convert_to_2d_vector(form_value):\n",
    "    return [1, 0] if form_value == 1 else [0, 1]\n",
    "\n",
    "def convert_to_4d_vector(term_value):\n",
    "    if term_value == 0:\n",
    "        return [1, 0, 0, 0]\n",
    "    elif term_value == 1:\n",
    "        return [0, 1, 0, 0]\n",
    "    elif term_value == 2:\n",
    "        return [0, 0, 1, 0]\n",
    "    elif term_value == 5:\n",
    "        return [0, 0, 0, 1]\n",
    "    \n",
    "# Apply the conversion function\n",
    "unique_forms['Form_Vector'] = unique_forms['Form'].apply(convert_to_2d_vector)\n",
    "form_vectors_array = np.array(unique_forms['Form_Vector'].tolist())\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_term['Term_Vector'] = unique_term['TermType'].apply(convert_to_4d_vector)\n",
    "term_vectors_array = np.array(unique_term['Term_Vector'].tolist())\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(unique_forms[['RGIId', 'Form_Vector']])\n",
    "# unique_forms['Form_Vector']\n",
    "# unique_term['Term_Vector']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600cff93-3431-4914-852b-1c031534f5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize_image(image_path, threshold=128):\n",
    "    \"\"\"\n",
    "    Reads an image and vectorizes it to 0 and 1 depending on the color.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: str, path to the image file\n",
    "\n",
    "    Returns:\n",
    "    - binary_vector: numpy array of 0s and 1s\n",
    "    \"\"\"\n",
    "    # Open the image and convert to RGB\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Define a blue color range\n",
    "    lower_blue = np.array([0, 0, 128])\n",
    "    upper_blue = np.array([127, 127, 255])\n",
    "    \n",
    "    # Create a mask for blue pixels\n",
    "    blue_mask = np.all((image_array >= lower_blue) & (image_array <= upper_blue), axis=-1)\n",
    "    \n",
    "    # Create a binary vector where blue is 1 and everything else is 0\n",
    "    binary_vector = blue_mask.astype(int)\n",
    "    \n",
    "    return binary_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "069bfe88-4955-46a5-96b4-72616b2c5e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Processes all images in the specified folder, vectorizing each one.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: str, path to the folder containing images\n",
    "\n",
    "    Returns:\n",
    "    - result_dict: dictionary, keys are image filenames and values are their binary vectors\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            binary_image = vectorize_image(image_path)\n",
    "            result_dict[filename] = binary_image\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fc70f44-cd1d-415a-b466-a328f8703e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = r'C:\\Users\\damsg\\OGGM\\glacier_geometries_images_small_rotmir'  \n",
    "processed_images = process_folder(folder_path)\n",
    "\n",
    "def resize_array(array, size=(64, 64)):\n",
    "    # Convert the array to PIL Image\n",
    "    image = Image.fromarray(np.array(array, dtype='uint8'))\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size, resample=Image.BILINEAR)\n",
    "    # Convert the resized image back to numpy array\n",
    "    return np.array(resized_image)\n",
    "\n",
    "# Assuming 'data_dict' is your dictionary containing multiple arrays\n",
    "resized_arrays = [resize_array(array) for array in processed_images.values()]\n",
    "\n",
    "# Stack all resized arrays into a single numpy array\n",
    "resized_data_array = np.stack(resized_arrays, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9088a0-f748-44e7-a1fc-6783a1a73358",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9329fa41-c660-4238-b264-f2c93c7ec761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_64 (Conv2D)          (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 650,308\n",
      "Trainable params: 650,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 4 #Change to 2 for form to 4 for Termtype\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=128,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=256,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Dropout(rate=0.60))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a5016afb-f3c6-453c-8457-ce0320d24a51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18568\n",
      "2321\n",
      "18568\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(resized_data_array))\n",
    "print(len(form_vectors_array))\n",
    "y = [form_vectors_array[i] for i in range(len(form_vectors_array)) for _ in range(8)]\n",
    "y1 = [term_vectors_array[i] for i in range(len(term_vectors_array)) for _ in range(8)]\n",
    "\n",
    "print(len(y))\n",
    "print(y[0])\n",
    "X = resized_data_array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size = 0.8, random_state=1)\n",
    "X_train0, X_test0, y_train1, y_test1 = train_test_split(X, y1,train_size = 0.8, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "32fea56e-5747-4a54-8771-8eb719d0960b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- TRAINING ---------\n",
      "465/465 [==============================] - 67s 142ms/step - loss: 1.1678 - categorical_accuracy: 0.6505 - val_loss: 0.8387 - val_categorical_accuracy: 0.8220\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['categorical_accuracy'])\n",
    "print('--------- TRAINING ---------')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x = np.array(X_train0), y = np.array(y_train1),validation_data=(np.array(X_test0), np.array(y_test1)), \n",
    "                    epochs = 1, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56237d1-d317-44a8-9d28-61cc64b4a8e4",
   "metadata": {},
   "source": [
    "## Normal NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9f3d7ec1-f743-425a-907e-c4a6932c1a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81290, 53)\n",
      "--------- TRAINING ---------\n",
      "Epoch 1/5\n",
      "2033/2033 [==============================] - 6s 3ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "2033/2033 [==============================] - 5s 3ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2033/2033 [==============================] - 6s 3ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2033/2033 [==============================] - 7s 3ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "2033/2033 [==============================] - 7s 4ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# X0 = glathida_rgis.drop(['ith_m','ith_f','THICKNESS','RGIId'],axis=1) \n",
    "X0 = glathida_rgis.drop(['Form','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "X0 = glathida_rgis.drop(['TermType','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X0 = pd.DataFrame(scaler.fit_transform(X0.values), columns=X0.columns, index=X0.index)\n",
    "# y0 = glathida_rgis['Form'] \n",
    "y0 = glathida_rgis['TermType'] \n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X0, y0,train_size = 0.8, random_state=1)\n",
    "print(np.shape(X0))\n",
    "model0 = Sequential([\n",
    "    Dense(54,activation='LeakyReLU'   ,name='input_layer'),\n",
    "    Dense(90,activation='relu'   ,name='hidden_layer1'),\n",
    "    Dense(90,activation='relu'   ,name='hidden_layer2'),\n",
    "    Dense(1, name='output')])\n",
    "\n",
    "model0.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "print('--------- TRAINING ---------')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model0.fit(x = np.array(X_train0), y = np.array(y_train0),validation_data=(np.array(X_test0), np.array(y_test0)), \n",
    "                    epochs = 5, callbacks=[early_stopping]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "01d9edbe-ef49-44c0-8bc1-51ed32132f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perm_importance = permutation_importance(model0, X_test0, y_test0, scoring ='neg_mean_absolute_error', n_repeats=5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a238a331-1705-433c-b164-f9b6468e603e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Zmed: 0.005709929073745945\n",
      "2. Aspect: 0.004124656653926662\n",
      "3. Form: 0.0032511009947928217\n",
      "4. POINT_LAT: 0.0028006188892364613\n",
      "5. RGI: 0.0015365256226289703\n",
      "6. aspect_gfa: 0.0013626384053841202\n",
      "7. aspect_300: 0.0010358497998848803\n",
      "8. Zmax: 0.00052399357424735\n",
      "9. smb: 0.0003666735084903561\n",
      "10. aspect_50: 0.00034876667908219084\n",
      "11. slope_lon_gf100: 0.00027349420798070676\n",
      "12. curv_300: 0.0002556475910718836\n",
      "13. slope_lon_gf300: 0.00022655289792580246\n",
      "14. dist_from_border_km_geom: 0.00018556618321193818\n",
      "15. slope_lon_gf450: 0.00015092586798735042\n",
      "16. slope_lat: 0.00010904609561013245\n",
      "17. vy_gf150: 0.00010066974887859014\n",
      "18. vx_gf150: 5.431998820853989e-05\n",
      "19. vx_gf300: 2.8750925930309813e-05\n",
      "20. curv_50: 2.5984332648920637e-05\n",
      "21. vy: 1.5212649709073211e-05\n",
      "22. vy_gf300: 1.2787207047448845e-05\n",
      "23. vy_gf100: 1.0764569195886864e-05\n",
      "24. vx_gfa: 3.74171580541649e-06\n",
      "25. vy_gf50: -1.527155426273019e-06\n",
      "26. dvx_dy: -3.333697056728813e-06\n",
      "27. dvy_dy: -8.650500142592943e-06\n",
      "28. dvy_dx: -1.2245427151635901e-05\n",
      "29. dvx_dx: -1.94867799252596e-05\n",
      "30. vx_gf50: -2.879515504654595e-05\n",
      "31. slope_lon: -2.953081705719951e-05\n",
      "32. vx_gf450: -3.111862729784365e-05\n",
      "33. vx: -4.066022293505167e-05\n",
      "34. vx_gf100: -4.5916789129529786e-05\n",
      "35. vy_gfa: -4.977516776323298e-05\n",
      "36. vy_gf450: -5.263788961068494e-05\n",
      "37. slope_lon_gf50: -7.352727193635778e-05\n",
      "38. curv_gfa: -9.014246897559586e-05\n",
      "39. slope_lat_gf150: -9.13107645754585e-05\n",
      "40. slope_lon_gfa: -0.00012600511830950233\n",
      "41. slope_lon_gf150: -0.00030718408019836385\n",
      "42. slope_lat_gf450: -0.00034425374863172875\n",
      "43. dmdtda_hugo: -0.00037978265949717427\n",
      "44. slope_lat_gf100: -0.00039420699730773333\n",
      "45. slope_lat_gfa: -0.00041090299455541767\n",
      "46. slope_lat_gf50: -0.0005488607635729115\n",
      "47. POINT_LON: -0.0006902447777461296\n",
      "48. slope_lat_gf300: -0.0007446552347615487\n",
      "49. Lmax: -0.0007498592138790227\n",
      "50. Area: -0.0010190315329951737\n",
      "51. Slope: -0.0015997448437967243\n",
      "52. elevation: -0.003058483017767144\n",
      "53. Zmin: -0.004330756908253608\n"
     ]
    }
   ],
   "source": [
    "# perm_importance = permutation_importance(model0, X_test0, y_test0, scoring ='neg_mean_absolute_error', n_repeats=5, random_state=42)\n",
    "\n",
    "feature_importance_scores = perm_importance.importances_mean\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X0.columns  # Assuming X is a pandas DataFrame with feature names\n",
    "\n",
    "# Print or visualize feature importance\n",
    "sorted_feature_indices = feature_importance_scores.argsort()[::-1]\n",
    "sorted_feature_names = feature_names[sorted_feature_indices]\n",
    "\n",
    "for i, feature_name in enumerate(sorted_feature_names):\n",
    "    print(f\"{i+1}. {feature_name}: {feature_importance_scores[sorted_feature_indices[i]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4b6f9-0901-46c0-b68f-487c7904789e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine CNN with NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa71172-485d-4581-9396-972cd97f5251",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Form CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d52eae9f-3974-417e-a4b3-d3764cb8bf49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 62, 62, 32)   320         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooling2D  (None, 31, 31, 32)  0           ['conv2d_24[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 29, 29, 64)   18496       ['max_pooling2d_24[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_25 (MaxPooling2D  (None, 14, 14, 64)  0           ['conv2d_25[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 12, 12, 128)  73856       ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_26 (MaxPooling2D  (None, 6, 6, 128)   0           ['conv2d_26[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 4, 4, 256)    295168      ['max_pooling2d_26[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_27 (MaxPooling2D  (None, 2, 2, 256)   0           ['conv2d_27[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 1024)         0           ['max_pooling2d_27[0][0]']       \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 64)           65600       ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 53)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 117)          0           ['dense_36[0][0]',               \n",
      "                                                                  'input_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 117)          13806       ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 180)          21240       ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 32)           5792        ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 1)            33          ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 494,311\n",
      "Trainable params: 494,311\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "num_features = 68 #Features in dataset\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 RGB images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(64 + num_features, activation='relu')(combined_input)\n",
    "fc2 = Dense(180, activation='relu')(fc1)\n",
    "fc3 = Dense(180, activation='relu')(fc2)\n",
    "fc3 = Dense(32, activation='relu')(fc2)\n",
    "output = Dense(1, activation='sigmoid')(fc3)  # Output layer for binary classification\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "combined_model.summary()\n",
    "\n",
    "\n",
    "# history = combined_model.fit(inputs = [resized_data_array,]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd00a871-ca2c-4017-baf5-ab4dab898fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = r'C:\\Users\\damsg\\OGGM\\glacier_geometries_images_small'  \n",
    "processed_images = process_folder(folder_path)\n",
    "\n",
    "def resize_array(array, size=(64, 64)):\n",
    "    # Convert the array to PIL Image\n",
    "    image = Image.fromarray(np.array(array, dtype='uint8'))\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size, resample=Image.BILINEAR)\n",
    "    # Convert the resized image back to numpy array\n",
    "    return np.array(resized_image)\n",
    "\n",
    "# Assuming 'data_dict' is your dictionary containing multiple arrays\n",
    "resized_arrays = [resize_array(array) for array in processed_images.values()]\n",
    "\n",
    "# Stack all resized arrays into a single numpy array\n",
    "resized_data_array = np.stack(resized_arrays, axis=0)\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_forms['Form_Vector'] = unique_forms['Form'].apply(convert_to_2d_vector)\n",
    "form_vectors_array = np.array(unique_forms['Form_Vector'].tolist())\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "unique_term['Term_Vector'] = unique_term['TermType'].apply(convert_to_4d_vector)\n",
    "term_vectors_array = np.array(unique_term['Term_Vector'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da67738b-7975-42c1-907f-13977435dec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68423, 64, 64)\n",
      "(68423,)\n"
     ]
    }
   ],
   "source": [
    "pictures = []\n",
    "current_rgi_id = None\n",
    "i = -1  # Initial value of i\n",
    "\n",
    "for rgi_id in glathida_rgis['RGIId']:\n",
    "    if rgi_id != current_rgi_id:\n",
    "        i += 1  # Increment i when RGIId changes\n",
    "        current_rgi_id = rgi_id\n",
    "    pictures.append(resized_data_array[i])\n",
    "\n",
    "# Convert pictures to a numpy array if needed\n",
    "pictures = np.array(pictures)\n",
    "print(np.shape(pictures))\n",
    "print(np.shape(glathida_rgis['RGIId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9454b251-2f2f-452d-8e58-e1d28dd491c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68423, 68)\n"
     ]
    }
   ],
   "source": [
    "# pictures = resized_data_array\n",
    "\n",
    "y01 = glathida_rgis['Form'] \n",
    "y02_values = glathida_rgis['TermType']\n",
    "\n",
    "y02 = np.array([convert_to_4d_vector(term_value) for term_value in y02_values])\n",
    "# y02_one_hot = [convert_to_4d_vector(term_value) for term_value in y02_values]\n",
    "\n",
    "# Convert the list to a numpy array if needed\n",
    "# y02 = np.array(y02_one_hot)\n",
    "\n",
    "\n",
    "y03 = glathida_rgis['THICKNESS']\n",
    "\n",
    "X01 = glathida_rgis.drop(['Form','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "X02 = glathida_rgis.drop(['TermType','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "X03 = glathida_rgis.drop(['RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "print(np.shape(X03))\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X01 = pd.DataFrame(scaler.fit_transform(X01.values), columns=X01.columns, index=X01.index)\n",
    "X02 = pd.DataFrame(scaler.fit_transform(X02.values), columns=X02.columns, index=X02.index)\n",
    "X03 = pd.DataFrame(scaler.fit_transform(X03.values), columns=X03.columns, index=X03.index)\n",
    "\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "\n",
    "X01_train, X01_test, y01_train, y01_test = train_test_split(X01, y01,train_size = 0.8, random_state=1)\n",
    "X02_train, X02_test, y02_train, y02_test = train_test_split(X02, y02,train_size = 0.8, random_state=1)\n",
    "X03_train, X03_test, y03_train, y03_test = train_test_split(X03, y03,train_size = 0.8, random_state=1)\n",
    "#Shooting for form\n",
    "pictures_train, pictures_val, X01_train, X01_val, y01_train, y01_val = train_test_split(\n",
    "    pictures, X01, y01, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define the early stopping callback\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_loss',  # Metric to monitor\n",
    "#     patience=2,          # Number of epochs with no improvement after which training will be stopped\n",
    "#     restore_best_weights=True  # Restore the weights of the best epoch\n",
    "# )\n",
    "# checkpoint = ModelCheckpoint(\n",
    "#     r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Form_model_weights_n0.h5',  # Full file path to save the model weights\n",
    "#     monitor='val_loss',               # Metric to monitor\n",
    "#     save_best_only=True,              # Save only the best weights\n",
    "#     save_weights_only=True            # Save only the weights (not the entire model)\n",
    "# )\n",
    "\n",
    "# combined_model.fit(\n",
    "#     [pictures_train, X01_train],  # Inputs: list of image data and non-image data\n",
    "#     y01_train,                    # Target labels\n",
    "#     epochs=7,                    # Number of epochs\n",
    "#     batch_size=32,                # Batch size\n",
    "#     validation_data=([pictures_val, X01_val], y01_val),  # Validation data\n",
    "#     callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    "# )\n",
    "# combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Form_model_weights_final_n0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc163ead-10e3-4c47-bbbc-de888c537be6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Termtype CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "591ac37d-6e88-49da-b6c4-1dade1613f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 62, 62, 32)   320         ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_20 (MaxPooling2D  (None, 31, 31, 32)  0           ['conv2d_20[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 29, 29, 64)   18496       ['max_pooling2d_20[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_21 (MaxPooling2D  (None, 14, 14, 64)  0           ['conv2d_21[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 12, 12, 128)  73856       ['max_pooling2d_21[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooling2D  (None, 6, 6, 128)   0           ['conv2d_22[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 4, 4, 256)    295168      ['max_pooling2d_22[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooling2D  (None, 2, 2, 256)   0           ['conv2d_23[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 1024)         0           ['max_pooling2d_23[0][0]']       \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 64)           65600       ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 68)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 132)          0           ['dense_30[0][0]',               \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 132)          17556       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 200)          26600       ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 32)           6432        ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 4)            132         ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 504,160\n",
      "Trainable params: 504,160\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "num_features = 68 #Features in dataset\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 Greyscale images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(64 + num_features, activation='relu')(combined_input)\n",
    "fc2 = Dense(200, activation='relu')(fc1)\n",
    "fc3 = Dense(220, activation='relu')(fc2)\n",
    "fc3 = Dense(32, activation='relu')(fc2)\n",
    "output = Dense(4, activation='sigmoid')(fc3)  # Output layer for multi classification\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "combined_model.summary()\n",
    "\n",
    "\n",
    "# history = combined_model.fit(inputs = [resized_data_array,]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c89c58d6-ab5c-426b-b974-a276eb41c83a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "2033/2033 [==============================] - 317s 155ms/step - loss: 0.1012 - accuracy: 0.9629 - val_loss: 0.0768 - val_accuracy: 0.9705\n",
      "Epoch 2/7\n",
      "2033/2033 [==============================] - 317s 156ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0455 - val_accuracy: 0.9814\n",
      "Epoch 3/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 4/7\n",
      "2033/2033 [==============================] - 324s 159ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 1.8127e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0138 - val_accuracy: 0.9945\n",
      "Epoch 6/7\n",
      "2033/2033 [==============================] - 317s 156ms/step - loss: 2.5115e-04 - accuracy: 0.9999 - val_loss: 2.7377e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 1.5606e-06 - accuracy: 1.0000 - val_loss: 7.9302e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Shooting for TermType\n",
    "pictures_train, pictures_val, X02_train, X02_val, y02_train, y02_val = train_test_split(\n",
    "    pictures, X02, y02, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=3,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Term_model_weights_n0.h5',  # Full file path to save the model weights\n",
    "    monitor='val_loss',               # Metric to monitor\n",
    "    save_best_only=True,              # Save only the best weights\n",
    "    save_weights_only=True            # Save only the weights (not the entire model)\n",
    ")\n",
    "# Train the model with early stopping\n",
    "combined_model.fit(\n",
    "    [pictures_train, X02_train],  # Inputs: list of image data and non-image data\n",
    "    y02_train,                    # Target labels\n",
    "    epochs=7,                    # Number of epochs\n",
    "    batch_size=32,                # Batch size\n",
    "    validation_data=([pictures_val, X02_val], y02_val),  # Validation data\n",
    "    callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    ")\n",
    "\n",
    "combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Term_model_weights_final_n0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f8a2a-a28b-47c4-acc6-977872f62bf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Thickness CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "222a0150-44d7-4abd-ace0-64607c832f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 62, 62, 32)   320         ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooling2D  (None, 31, 31, 32)  0           ['conv2d_32[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 29, 29, 64)   18496       ['max_pooling2d_32[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_33 (MaxPooling2D  (None, 14, 14, 64)  0           ['conv2d_33[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 12, 12, 128)  73856       ['max_pooling2d_33[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_34 (MaxPooling2D  (None, 6, 6, 128)   0           ['conv2d_34[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 4, 4, 256)    295168      ['max_pooling2d_34[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooling2D  (None, 2, 2, 256)   0           ['conv2d_35[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 1024)         0           ['max_pooling2d_35[0][0]']       \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 64)           65600       ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 68)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 132)          0           ['dense_48[0][0]',               \n",
      "                                                                  'input_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 132)          17556       ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 175)          23275       ['dense_49[0][0]']               \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 32)           5632        ['dense_50[0][0]']               \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 1)            33          ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 499,936\n",
      "Trainable params: 499,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_features = 68 #Features in dataset\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 RGB images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(64 + num_features, activation='relu')(combined_input)\n",
    "fc2 = Dense(175, activation='relu')(fc1)\n",
    "fc3 = Dense(75, activation='relu')(fc2)\n",
    "fc3 = Dense(32, activation='relu')(fc2)\n",
    "output = Dense(1)(fc3)  # Output layer for regression\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam',loss= 'mean_absolute_error',metrics=['mean_absolute_error'])\n",
    "# Print the model summary\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c2f08837-7c87-4d21-8a53-fa81bf4c054c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1711/1711 [==============================] - 222s 130ms/step - loss: 26.9555 - mean_absolute_error: 26.9555 - val_loss: 29.0544 - val_mean_absolute_error: 29.0544\n",
      "Epoch 2/10\n",
      "1711/1711 [==============================] - 249s 146ms/step - loss: 26.8785 - mean_absolute_error: 26.8785 - val_loss: 28.5250 - val_mean_absolute_error: 28.5250\n",
      "Epoch 3/10\n",
      "1711/1711 [==============================] - 237s 138ms/step - loss: 26.7258 - mean_absolute_error: 26.7258 - val_loss: 29.4380 - val_mean_absolute_error: 29.4380\n",
      "Epoch 4/10\n",
      "1711/1711 [==============================] - 229s 134ms/step - loss: 26.6780 - mean_absolute_error: 26.6780 - val_loss: 28.9008 - val_mean_absolute_error: 28.9008\n",
      "Epoch 5/10\n",
      "1711/1711 [==============================] - 245s 143ms/step - loss: 26.4787 - mean_absolute_error: 26.4787 - val_loss: 28.3164 - val_mean_absolute_error: 28.3164\n",
      "Epoch 6/10\n",
      "1711/1711 [==============================] - 209s 122ms/step - loss: 26.3903 - mean_absolute_error: 26.3903 - val_loss: 28.1410 - val_mean_absolute_error: 28.1410\n",
      "Epoch 7/10\n",
      "1711/1711 [==============================] - 246s 144ms/step - loss: 26.1462 - mean_absolute_error: 26.1462 - val_loss: 28.2047 - val_mean_absolute_error: 28.2047\n",
      "Epoch 8/10\n",
      "1711/1711 [==============================] - 246s 144ms/step - loss: 26.1835 - mean_absolute_error: 26.1835 - val_loss: 28.2512 - val_mean_absolute_error: 28.2512\n",
      "Epoch 9/10\n",
      "1711/1711 [==============================] - 248s 145ms/step - loss: 26.0372 - mean_absolute_error: 26.0372 - val_loss: 28.3994 - val_mean_absolute_error: 28.3994\n"
     ]
    }
   ],
   "source": [
    "#Shooting for Thickness\n",
    "pictures_train, pictures_val, X03_train, X03_val, y03_train, y03_val = train_test_split(\n",
    "    pictures, X03, y03, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=3,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Thick_model_weights_n0.h5',  # Full file path to save the model weights\n",
    "    monitor='val_loss',               # Metric to monitor\n",
    "    save_best_only=True,              # Save only the best weights\n",
    "    save_weights_only=True            # Save only the weights (not the entire model)\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "combined_model.fit(\n",
    "    [pictures_train, X03_train],  # Inputs: list of image data and non-image data\n",
    "    y03_train,                    # Target labels\n",
    "    epochs=10,                   # Number of epochs\n",
    "    batch_size=32,                # Batch size\n",
    "    validation_data=([pictures_val, X03_val], y03_val),  # Validation data\n",
    "    callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    ")\n",
    "\n",
    "combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Thick_model_weights_final_n0.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc8c80-7b08-4696-bf95-5640edc122f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_model.load_weights('r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/model_weights_final.h5'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89615cf3-7923-4431-bc40-bf59df44a95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(np.shape(pictures))\n",
    "# print(np.shape(glathida_rgis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "424d1ae1-c67d-46d4-9eda-6109e8cf7c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 31, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 2, 2, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,840\n",
      "Trainable params: 387,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1711/1711 [==============================] - 31s 18ms/step\n",
      "428/428 [==============================] - 8s 19ms/step\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.806882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 242087\n",
      "[LightGBM] [Info] Number of data points in the train set: 54738, number of used features: 1088\n",
      "[LightGBM] [Info] Start training from score 150.256401\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's l1: 16.7314\tvalid_1's l1: 23.0035\n",
      "Mean Absolute Error on validation set: 23.00348177499582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "# Assuming pictures, X03, and y03 are your image data, non-image feature data, and target values respectively\n",
    "# pictures = np.array([...])  # Your image data (64x64x1)\n",
    "# X03 = np.array([...])  # Your non-image feature data\n",
    "# y03 = np.array([...])  # Your target values\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "pictures_train, pictures_val, X03_train, X03_val, y03_train, y03_val = train_test_split(\n",
    "    pictures, X03, y03, test_size=0.2, random_state=42)\n",
    "\n",
    "num_features = X03.shape[1]  # Number of non-image features\n",
    "\n",
    "# Define the CNN model for feature extraction\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 grayscale images\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Define the model to output the flattened features\n",
    "feature_extraction_model = Model(inputs=image_input, outputs=flatten)\n",
    "feature_extraction_model.summary()\n",
    "\n",
    "# Extract features from the training and validation image data\n",
    "image_features_train = feature_extraction_model.predict(pictures_train)\n",
    "image_features_val = feature_extraction_model.predict(pictures_val)\n",
    "\n",
    "# Combine image features with non-image data\n",
    "combined_train_data = np.concatenate([image_features_train, X03_train], axis=1)\n",
    "combined_val_data = np.concatenate([image_features_val, X03_val], axis=1)\n",
    "\n",
    "# Create LightGBM datasets for training and validation\n",
    "train_data = lgb.Dataset(combined_train_data, label=y03_train)\n",
    "val_data = lgb.Dataset(combined_val_data, label=y03_val, reference=train_data)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Train the LightGBM model with early stopping\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    callbacks=[early_stopping(stopping_rounds=10)]\n",
    ")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions_val = gbm.predict(combined_val_data)\n",
    "\n",
    "# Evaluate the model (example: Mean Absolute Error)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y03_val, predictions_val)\n",
    "print(f'Mean Absolute Error on validation set: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73df68-ed34-467d-adac-d9eb2dbaf845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c95011-d1e6-4bf4-8da8-bc8223608d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76ed22-8796-4def-8cf3-00345ef5151e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a3c33edd-39ec-4e32-992c-f3a478fa4463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 188 ms\n",
      "Wall time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metadata_file2 = \"no_zeros_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "glathida_rgis2 = pd.read_csv(metadata_file2, low_memory=False)\n",
    "glathida_rgis2 = glathida_rgis2.dropna()\n",
    "\n",
    "test = []\n",
    "for i in range(len(pictures)):\n",
    "    test.append(pictures[i].flatten())\n",
    "glathida_rgis2['PICTURE'] = test\n",
    "glathida_rgis2.to_csv('n0_wpics_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6efac976-835a-40c1-ace9-4805fc994359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "\n",
    "# The objective function will include the LightGBM model and the hyperparameters to be optimized.\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to be optimized\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'verbose':[-1]\n",
    "    }\n",
    "    \n",
    "   \n",
    "    # run the model, fit and predict \n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric='rmse',\n",
    "        #early_stopping_rounds=100,\n",
    "        callbacks=[LightGBMPruningCallback(trial, 'rmse')],\n",
    "        #verbose=False\n",
    "    )\n",
    "    \n",
    "    y_preds = model.predict(X_valid) # num_iteration=model.best_iteration)\n",
    "    \n",
    "    rmse = mean_squared_error(y_valid, y_preds, squared=False)\n",
    "    MAE = mean_absolute_error(y_valid, y_preds)\n",
    "    R2 = r2_score(y_valid, y_preds)\n",
    "    \n",
    "    return MAE\n",
    "\n",
    "# create a study and start the optimization process:\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a33ce0-8a80-47bf-993b-c38c46a41731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a study and start the optimization process:\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0553ef-e6fa-436d-99f4-989f44b4159f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9b812598-007b-4de1-b1ae-57f66f65b7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1711/1711 [==============================] - 49s 29ms/step\n",
      "428/428 [==============================] - 5s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-05 11:27:43,180] A new study created in memory with name: no-name-f61cbc8c-a17b-4797-b44d-e23df29eaa4b\n",
      "[I 2024-06-05 11:29:09,070] Trial 0 finished with value: 19.678013591840312 and parameters: {'lambda_l1': 43.641468570081535, 'lambda_l2': 10.550268394277476, 'num_leaves': 1105, 'feature_fraction': 0.7598472545116572, 'bagging_fraction': 0.9886745729885776, 'bagging_freq': 3, 'min_child_samples': 37}. Best is trial 0 with value: 19.678013591840312.\n",
      "[I 2024-06-05 11:29:34,333] Trial 1 finished with value: 26.3101888361896 and parameters: {'lambda_l1': 43.31769764878592, 'lambda_l2': 41.526627538936914, 'num_leaves': 230, 'feature_fraction': 0.7538247780511088, 'bagging_fraction': 0.8299381887715898, 'bagging_freq': 7, 'min_child_samples': 232}. Best is trial 0 with value: 19.678013591840312.\n",
      "[I 2024-06-05 11:30:23,828] Trial 2 finished with value: 21.823651454792547 and parameters: {'lambda_l1': 44.3473269613546, 'lambda_l2': 24.207908271101765, 'num_leaves': 907, 'feature_fraction': 0.7220650451059192, 'bagging_fraction': 0.9586988538000203, 'bagging_freq': 3, 'min_child_samples': 87}. Best is trial 0 with value: 19.678013591840312.\n",
      "[I 2024-06-05 11:30:53,196] Trial 3 finished with value: 24.294859343865912 and parameters: {'lambda_l1': 26.30489554589707, 'lambda_l2': 38.16856469439492, 'num_leaves': 1560, 'feature_fraction': 0.5015035449820724, 'bagging_fraction': 0.9310713447991654, 'bagging_freq': 9, 'min_child_samples': 153}. Best is trial 0 with value: 19.678013591840312.\n",
      "[I 2024-06-05 11:32:22,032] Trial 4 finished with value: 21.131918038058124 and parameters: {'lambda_l1': 3.8670991562635644, 'lambda_l2': 2.143284288089347, 'num_leaves': 2012, 'feature_fraction': 0.8930215992843344, 'bagging_fraction': 0.8680299318566838, 'bagging_freq': 8, 'min_child_samples': 65}. Best is trial 0 with value: 19.678013591840312.\n",
      "[I 2024-06-05 11:32:28,166] Trial 5 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:32:34,294] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:32:41,122] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:32:48,827] Trial 8 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:32:56,160] Trial 9 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:34:47,430] Trial 10 finished with value: 19.499478316650826 and parameters: {'lambda_l1': 15.945314364665494, 'lambda_l2': 3.4109439325748205, 'num_leaves': 1143, 'feature_fraction': 0.5718688977898352, 'bagging_fraction': 0.9986859200516998, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 10 with value: 19.499478316650826.\n",
      "[I 2024-06-05 11:37:02,755] Trial 11 finished with value: 19.582313330167736 and parameters: {'lambda_l1': 12.634592611404694, 'lambda_l2': 1.9348941771545576, 'num_leaves': 1194, 'feature_fraction': 0.5551233231468121, 'bagging_fraction': 0.9943310535235088, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 10 with value: 19.499478316650826.\n",
      "[I 2024-06-05 11:39:21,051] Trial 12 finished with value: 19.773563810701024 and parameters: {'lambda_l1': 13.693832396933908, 'lambda_l2': 1.4955570935280151, 'num_leaves': 1127, 'feature_fraction': 0.5413878776494718, 'bagging_fraction': 0.9968289952692236, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 10 with value: 19.499478316650826.\n",
      "[I 2024-06-05 11:40:58,873] Trial 13 finished with value: 19.935462077207827 and parameters: {'lambda_l1': 9.990787986565532, 'lambda_l2': 10.724979106231771, 'num_leaves': 669, 'feature_fraction': 0.584564050678217, 'bagging_fraction': 0.8850240678065922, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 10 with value: 19.499478316650826.\n",
      "[I 2024-06-05 11:41:08,464] Trial 14 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:41:16,753] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:41:23,415] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:41:31,158] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:42:30,461] Trial 18 pruned. Trial was pruned at iteration 54.\n",
      "[I 2024-06-05 11:45:34,677] Trial 19 finished with value: 19.158848900852867 and parameters: {'lambda_l1': 5.193669120991808, 'lambda_l2': 5.697527154203639, 'num_leaves': 1248, 'feature_fraction': 0.6782795729230542, 'bagging_fraction': 0.998037589926326, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 11:45:42,862] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:48:31,209] Trial 21 finished with value: 19.504435158732424 and parameters: {'lambda_l1': 6.174326543140499, 'lambda_l2': 6.27320595026601, 'num_leaves': 1325, 'feature_fraction': 0.6194099451867623, 'bagging_fraction': 0.9935036234617758, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 11:48:38,701] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:50:53,256] Trial 23 finished with value: 19.574588810130276 and parameters: {'lambda_l1': 6.4251203438366815, 'lambda_l2': 7.500041644793337, 'num_leaves': 909, 'feature_fraction': 0.6020652593683379, 'bagging_fraction': 0.9988161321816185, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 11:51:00,675] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:51:08,896] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:51:16,364] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:51:24,311] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:51:32,569] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:51:40,152] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:51:47,509] Trial 30 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:54:21,039] Trial 31 finished with value: 19.525595957737885 and parameters: {'lambda_l1': 5.6108227701010955, 'lambda_l2': 4.638217171667023, 'num_leaves': 1120, 'feature_fraction': 0.6027064478768711, 'bagging_fraction': 0.9960716420818249, 'bagging_freq': 4, 'min_child_samples': 8}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 11:54:28,300] Trial 32 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:54:36,988] Trial 33 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:54:45,950] Trial 34 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:54:54,906] Trial 35 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:55:03,649] Trial 36 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:55:15,525] Trial 37 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-06-05 11:55:24,709] Trial 38 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:55:41,411] Trial 39 pruned. Trial was pruned at iteration 16.\n",
      "[I 2024-06-05 11:55:50,821] Trial 40 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:56:00,217] Trial 41 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:56:09,449] Trial 42 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:56:18,878] Trial 43 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:56:39,557] Trial 44 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-06-05 11:56:48,283] Trial 45 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:56:57,562] Trial 46 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:57:07,460] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:57:17,004] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:57:26,003] Trial 49 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:57:35,237] Trial 50 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 11:59:37,711] Trial 51 pruned. Trial was pruned at iteration 78.\n",
      "[I 2024-06-05 11:59:45,123] Trial 52 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:00:40,138] Trial 53 pruned. Trial was pruned at iteration 45.\n",
      "[I 2024-06-05 12:00:47,793] Trial 54 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:00:55,076] Trial 55 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:01:02,224] Trial 56 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:01:09,445] Trial 57 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:01:16,199] Trial 58 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:01:22,726] Trial 59 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:01:29,402] Trial 60 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:01:36,637] Trial 61 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:01:47,312] Trial 62 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:01:53,964] Trial 63 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:03:34,226] Trial 64 pruned. Trial was pruned at iteration 80.\n",
      "[I 2024-06-05 12:03:40,919] Trial 65 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:03:47,613] Trial 66 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:03:54,727] Trial 67 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:04:01,599] Trial 68 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:04:08,255] Trial 69 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:04:15,325] Trial 70 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:04:53,021] Trial 71 pruned. Trial was pruned at iteration 36.\n",
      "[I 2024-06-05 12:05:00,321] Trial 72 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:05:11,783] Trial 73 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-06-05 12:05:18,261] Trial 74 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:05:25,583] Trial 75 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:05:33,006] Trial 76 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:06:59,496] Trial 77 pruned. Trial was pruned at iteration 56.\n",
      "[I 2024-06-05 12:07:06,402] Trial 78 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:07:20,425] Trial 79 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-06-05 12:09:29,784] Trial 80 finished with value: 19.55486928259931 and parameters: {'lambda_l1': 15.368628030335703, 'lambda_l2': 2.6035748635897225, 'num_leaves': 858, 'feature_fraction': 0.7319470040388235, 'bagging_fraction': 0.9037940408934508, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 12:11:45,702] Trial 81 finished with value: 19.406288189903336 and parameters: {'lambda_l1': 14.986542597965158, 'lambda_l2': 2.194624950382693, 'num_leaves': 806, 'feature_fraction': 0.7640705019866398, 'bagging_fraction': 0.9110155288261015, 'bagging_freq': 3, 'min_child_samples': 11}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 12:12:48,466] Trial 82 pruned. Trial was pruned at iteration 41.\n",
      "[I 2024-06-05 12:12:56,539] Trial 83 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:13:04,628] Trial 84 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:13:11,823] Trial 85 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:13:51,071] Trial 86 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-06-05 12:13:57,139] Trial 87 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:14:10,159] Trial 88 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:14:28,715] Trial 89 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:14:46,684] Trial 90 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:17:10,450] Trial 91 finished with value: 19.570435289121733 and parameters: {'lambda_l1': 14.953580162262881, 'lambda_l2': 1.2982568206808875, 'num_leaves': 1020, 'feature_fraction': 0.5518562578594768, 'bagging_fraction': 0.9953869060968896, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 12:18:03,030] Trial 92 pruned. Trial was pruned at iteration 48.\n",
      "[I 2024-06-05 12:18:09,626] Trial 93 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:20:06,781] Trial 94 finished with value: 19.503752989335965 and parameters: {'lambda_l1': 12.652575373269606, 'lambda_l2': 3.8091598302106746, 'num_leaves': 926, 'feature_fraction': 0.6233693151720212, 'bagging_fraction': 0.9941714192825397, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 12:22:03,661] Trial 95 finished with value: 19.59731464969182 and parameters: {'lambda_l1': 12.603126547235611, 'lambda_l2': 2.584354733398228, 'num_leaves': 877, 'feature_fraction': 0.6344915632082218, 'bagging_fraction': 0.9850901639463149, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 12:24:02,620] Trial 96 finished with value: 19.64221737711963 and parameters: {'lambda_l1': 16.223860904739578, 'lambda_l2': 0.07501118544929408, 'num_leaves': 913, 'feature_fraction': 0.6644795390907162, 'bagging_fraction': 0.9948337016943215, 'bagging_freq': 3, 'min_child_samples': 17}. Best is trial 19 with value: 19.158848900852867.\n",
      "[I 2024-06-05 12:24:21,755] Trial 97 pruned. Trial was pruned at iteration 16.\n",
      "[I 2024-06-05 12:24:28,887] Trial 98 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-05 12:24:35,588] Trial 99 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 19.158848900852867\n",
      "  Params: \n",
      "    lambda_l1: 5.193669120991808\n",
      "    lambda_l2: 5.697527154203639\n",
      "    num_leaves: 1248\n",
      "    feature_fraction: 0.6782795729230542\n",
      "    bagging_fraction: 0.998037589926326\n",
      "    bagging_freq: 4\n",
      "    min_child_samples: 7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "pictures_train, pictures_val, X03_train, X03_val, y03_train, y03_val = train_test_split(\n",
    "    pictures, X03, y03, test_size=0.2, random_state=42)\n",
    "\n",
    "num_features = X03.shape[1]  # Number of non-image features\n",
    "\n",
    "# Define the CNN model for feature extraction\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 grayscale images\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Define the model to output the flattened features\n",
    "feature_extraction_model = Model(inputs=image_input, outputs=flatten)\n",
    "# feature_extraction_model.summary()\n",
    "\n",
    "# Extract features from the training and validation image data\n",
    "image_features_train = feature_extraction_model.predict(pictures_train)\n",
    "image_features_val = feature_extraction_model.predict(pictures_val)\n",
    "\n",
    "# Combine image features with non-image data\n",
    "combined_train_data = np.concatenate([image_features_train, X03_train], axis=1)\n",
    "combined_val_data = np.concatenate([image_features_val, X03_val], axis=1)\n",
    "\n",
    "# The objective function for Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 50.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 50.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 128, 2048),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 0.9),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.75, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 250),\n",
    "    }\n",
    "\n",
    "    # run the model, fit and predict \n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(\n",
    "        combined_train_data, y03_train,\n",
    "        eval_set=[(combined_val_data, y03_val)],\n",
    "        eval_metric='rmse',\n",
    "        callbacks=[LightGBMPruningCallback(trial, 'rmse')]\n",
    "    )\n",
    "    \n",
    "    y_preds = model.predict(combined_val_data)\n",
    "    \n",
    "    mae = mean_absolute_error(y03_val, y_preds)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Create a study and start the optimization process\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('  Value: {}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266cc27-ee19-4dfe-af9f-8bfceee5bd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b196cc-9b77-4eb3-9591-a4ea01e67ae4",
   "metadata": {},
   "source": [
    "1st try\n",
    "Best trial:\n",
    "  Value: 21.53931570838462\n",
    "  Params: \n",
    "    lambda_l1: 2.01546274100036\n",
    "    lambda_l2: 0.7111412857087858\n",
    "    num_leaves: 242\n",
    "    feature_fraction: 0.6227918411296163\n",
    "    bagging_fraction: 0.9655103122297912\n",
    "    bagging_freq: 7\n",
    "    min_child_samples: 27\n",
    "\n",
    "2nd try Increased the parameter space notably \n",
    "num leaves (2,256) -> (128,1024)\n",
    "min_clild_samples (5,100) -> (10,250)\n",
    "Best trial:\n",
    "  Value: 19.440244621935555\n",
    "  Params: \n",
    "    lambda_l1: 9.942178625506006\n",
    "    lambda_l2: 6.021388788503392\n",
    "    num_leaves: 927\n",
    "    feature_fraction: 0.7971447195854893\n",
    "    bagging_fraction: 0.9630138347471484\n",
    "    bagging_freq: 5\n",
    "    min_child_samples: 25\n",
    "    \n",
    "3nd try Increased the parameter space notably \n",
    "num leaves             (2,256) -> (128,2048)\n",
    "'lambda_l1':           (1e-8, 10.0) -> (1e-8, 50.0)\n",
    "'lambda_l2':           (1e-8, 10.0) -> (1e-8, 50.0)\n",
    "feature_fraction':     (0.4, 1.0) -> (0.5, 0.9)\n",
    "Best trial:\n",
    "  Value: 18.961424118310052\n",
    "  Params: \n",
    "    lambda_l1: 48.11818528734888\n",
    "    lambda_l2: 6.7716539555661415\n",
    "    num_leaves: 1892\n",
    "    feature_fraction: 0.6871792889443591\n",
    "    bagging_fraction: 0.9856255101027098\n",
    "    bagging_freq: 1\n",
    "    min_child_samples: 14\n",
    "\n",
    "4th try Increased the parameter space notably \n",
    "'rmse' -> mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "24f655f1-88a0-4699-97cc-5b99696b5e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 18.961424118310052\n",
      "Root Mean Squared Error: 35.85037670426074\n",
      "R^2 Score: 0.9539464302988118\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': 48.11818528734888,\n",
    "    'lambda_l2': 6.7716539555661415,\n",
    "    'num_leaves': 1892,\n",
    "    'feature_fraction': 0.6871792889443591,\n",
    "    'bagging_fraction': 0.9856255101027098,\n",
    "    'bagging_freq': 1,\n",
    "    'min_child_samples': 14\n",
    "}\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Assuming combined_train_data, y03_train, combined_val_data, y03_val are already defined\n",
    "\n",
    "# Create the LightGBM regressor with the best hyperparameters\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(\n",
    "    combined_train_data, y03_train,\n",
    "    eval_set=[(combined_val_data, y03_val)],\n",
    "    eval_metric='rmse',\n",
    ")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_preds = model.predict(combined_val_data)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y03_val, y_preds)\n",
    "rmse = mean_squared_error(y03_val, y_preds, squared=False)\n",
    "r2 = r2_score(y03_val, y_preds)\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2ddbef84-006a-4dd6-9c7d-127d0ccde5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation_plot(estimator, y_test, y_pred):\n",
    "    # input: estimator = xgb_cl - XGBClassifier with all the hyperparameter, for example\n",
    "    # input: y_test = we divided our y (labeled feature we want to know) into train, test, validation, y_test is the part from test \n",
    "    # input: y_pred = is the y values predicted for the X_test\n",
    "    # plot the figures from the feedback document of the inital project in applied machine learning 2024 \n",
    "    # (Diversion, Distribution Residuals and Relative Errors)\n",
    "    # checked 04/06/2024\n",
    "\n",
    "    y_test = np.array(y_test) \n",
    "    residuals = y_test - y_pred\n",
    "    relative_errors = residuals / np.abs(y_test)\n",
    "    relative_errors = relative_errors[np.abs(relative_errors) <= 1.5]\n",
    "    percentile_90 = np.percentile(np.abs(residuals), 90)\n",
    "    high_residual_mask = np.abs(residuals) <= percentile_90\n",
    "\n",
    "    # Plot the Distribution of the Residuals and the Relative Errors\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    ax1.hist(residuals, bins='auto')\n",
    "    ax1.set_title('Distribution of Residuals')\n",
    "    ax1.set_xlabel('Residuals')\n",
    "    ax1.set_ylabel('Count')\n",
    "    #ax1.set_xlim()\n",
    "    \n",
    "    ax2.hist(relative_errors, bins='auto')\n",
    "    ax2.set_title('Distribution of Relative Errors')\n",
    "    ax2.set_xlabel('Relative Prediction Error')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_xlim(-1.5, 1.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the Diversion\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, c='blue', alpha=0.1, label='100th percentile')\n",
    "    plt.scatter(y_test[high_residual_mask], y_pred[high_residual_mask], c='green', alpha=0.1, label='residual <= 90th percentile')\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='orange', linewidth=2)\n",
    "    # plt.ylim((0,1250))\n",
    "    # plt.xlim((0,1250))\n",
    "    \n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.title('Diversion')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the RMSE for training and validation sets\n",
    "    results = estimator.evals_result()\n",
    "    epochs = len(results['validation_0']['mae'])\n",
    "    x_axis = range(0, epochs)\n",
    "\n",
    "    # Plot RMSE and MAE metric\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    ax1.plot(x_axis, results['validation_0']['rmse'], label='Train')\n",
    "    ax1.plot(x_axis, results['validation_1']['rmse'], label='Test')\n",
    "    ax1.plot(x_axis, results['validation_2']['rmse'], label='Validation')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('RMSE')\n",
    "    ax1.set_title('Evolution of the Root Mean Squared Error')\n",
    "\n",
    "    ax2.plot(x_axis, results['validation_0']['mae'], label='Train')\n",
    "    ax2.plot(x_axis, results['validation_1']['mae'], label='Test')\n",
    "    ax2.plot(x_axis, results['validation_2']['mae'], label='Validation')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_title('Evolution of the Mean Absolute Error')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d6f70390-49b1-4ea3-97bb-7815afa1bceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LGBMRegressor' object has no attribute 'evals_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluation_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43my03_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_preds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[134], line 47\u001b[0m, in \u001b[0;36mevaluation_plot\u001b[1;34m(estimator, y_test, y_pred)\u001b[0m\n\u001b[0;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Plot the RMSE for training and validation sets\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevals_result\u001b[49m()\n\u001b[0;32m     48\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     49\u001b[0m x_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, epochs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LGBMRegressor' object has no attribute 'evals_result'"
     ]
    }
   ],
   "source": [
    "evaluation_plot(model,y03_val, y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa7922-3ae9-494f-9244-86dde1941dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
