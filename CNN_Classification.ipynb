{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96890011-0d5e-4b6b-860e-3898c2e0ce7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import oggm\n",
    "from oggm import utils\n",
    "\n",
    "from __future__ import print_function, division   # Ensures Python3 printing & division standard\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,mean_squared_error, mean_absolute_error, r2_score, roc_curve,auc\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,export_graphviz\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV, cross_val_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from scipy.stats import randint, poisson\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "\n",
    "import csv\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "# %matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b1d5ca-1e13-4ebd-9c3c-318c8cec4414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.47058824e-02 1.49253731e-02 2.08333333e-02 ... 3.09633333e+03\n",
      " 3.10661905e+03 3.13554545e+03]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(73111, 59)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_file = \"n0_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "glathida_rgis = pd.read_csv(metadata_file, low_memory=False)\n",
    "print(np.unique(glathida_rgis['THICKNESS']))\n",
    "np.shape(glathida_rgis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef305a2-c83d-4e6b-9664-50d4701d6bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73111, 72)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# metadata_file = \"metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "# glathida_rgis = pd.read_csv(metadata_file, low_memory=False)\n",
    "# df3 = glathida_rgis.drop(glathida_rgis[glathida_rgis['THICKNESS'] < 0.5].index)\n",
    "\n",
    "# print(np.shape(df3))\n",
    "\n",
    "metadata_file = \"n0_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "glathida_rgis = pd.read_csv(metadata_file, low_memory=False)\n",
    "\n",
    "# glathida_rgis['lat'] = glathida_rgis['POINT_LAT']\n",
    "glathida_rgis['v50'] = np.sqrt(glathida_rgis['vx_gf50']**2 + glathida_rgis['vy_gf50']**2)\n",
    "glathida_rgis['v100'] = np.sqrt(glathida_rgis['vx_gf100']**2 + glathida_rgis['vy_gf100']**2)\n",
    "glathida_rgis['v150'] = np.sqrt(glathida_rgis['vx_gf150']**2 + glathida_rgis['vy_gf150']**2)\n",
    "glathida_rgis['v300'] = np.sqrt(glathida_rgis['vx_gf300']**2 + glathida_rgis['vy_gf300']**2)\n",
    "glathida_rgis['v450'] = np.sqrt(glathida_rgis['vx_gf450']**2 + glathida_rgis['vy_gf450']**2)\n",
    "glathida_rgis['vgfa'] = np.sqrt(glathida_rgis['vx_gfa']**2 + glathida_rgis['vy_gfa']**2)\n",
    "glathida_rgis['dvx'] = np.sqrt(glathida_rgis['dvx_dx']**2 + glathida_rgis['dvx_dy']**2)\n",
    "\n",
    "glathida_rgis['slope50'] = np.sqrt(glathida_rgis['slope_lon_gf50']**2 + glathida_rgis['slope_lat_gf50']**2)\n",
    "glathida_rgis['slope100'] = np.sqrt(glathida_rgis['slope_lon_gf100']**2 + glathida_rgis['slope_lat_gf100']**2)\n",
    "glathida_rgis['slope150'] = np.sqrt(glathida_rgis['slope_lon_gf150']**2 + glathida_rgis['slope_lat_gf150']**2)\n",
    "glathida_rgis['slope300'] = np.sqrt(glathida_rgis['slope_lon_gf300']**2 + glathida_rgis['slope_lat_gf300']**2)\n",
    "glathida_rgis['slope450'] = np.sqrt(glathida_rgis['slope_lon_gf450']**2 + glathida_rgis['slope_lat_gf450']**2)\n",
    "glathida_rgis['slopegfa'] = np.sqrt(glathida_rgis['slope_lon_gfa']**2 + glathida_rgis['slope_lat_gfa']**2)\n",
    "# glathida_rgis['elevation_from_zmin'] = glathida_rgis['elevation'] - glathida_rgis['Zmin']\n",
    "\n",
    "print(np.shape(glathida_rgis))\n",
    "\n",
    "# Group by 'RGIId' and get the unique 'Form' value for each 'RGIId'\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "# Function to convert 'Form' value to 2D vector\n",
    "def convert_to_2d_vector(form_value):\n",
    "    return [1, 0] if form_value == 1 else [0, 1]\n",
    "\n",
    "def convert_to_4d_vector(term_value):\n",
    "    if term_value == 0:\n",
    "        return [1, 0, 0, 0]\n",
    "    elif term_value == 1:\n",
    "        return [0, 1, 0, 0]\n",
    "    elif term_value == 2:\n",
    "        return [0, 0, 1, 0]\n",
    "    elif term_value == 5:\n",
    "        return [0, 0, 0, 1]\n",
    "    \n",
    "# Apply the conversion function\n",
    "unique_forms['Form_Vector'] = unique_forms['Form'].apply(convert_to_2d_vector)\n",
    "form_vectors_array = np.array(unique_forms['Form_Vector'].tolist())\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_term['Term_Vector'] = unique_term['TermType'].apply(convert_to_4d_vector)\n",
    "term_vectors_array = np.array(unique_term['Term_Vector'].tolist())\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(unique_forms[['RGIId', 'Form_Vector']])\n",
    "# unique_forms['Form_Vector']\n",
    "# unique_term['Term_Vector']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600cff93-3431-4914-852b-1c031534f5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize_image(image_path, threshold=128):\n",
    "    \"\"\"\n",
    "    Reads an image and vectorizes it to 0 and 1 depending on the color.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: str, path to the image file\n",
    "\n",
    "    Returns:\n",
    "    - binary_vector: numpy array of 0s and 1s\n",
    "    \"\"\"\n",
    "    # Open the image and convert to RGB\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Define a blue color range\n",
    "    lower_blue = np.array([0, 0, 128])\n",
    "    upper_blue = np.array([127, 127, 255])\n",
    "    \n",
    "    # Create a mask for blue pixels\n",
    "    blue_mask = np.all((image_array >= lower_blue) & (image_array <= upper_blue), axis=-1)\n",
    "    \n",
    "    # Create a binary vector where blue is 1 and everything else is 0\n",
    "    binary_vector = blue_mask.astype(int)\n",
    "    \n",
    "    return binary_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069bfe88-4955-46a5-96b4-72616b2c5e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Processes all images in the specified folder, vectorizing each one.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: str, path to the folder containing images\n",
    "\n",
    "    Returns:\n",
    "    - result_dict: dictionary, keys are image filenames and values are their binary vectors\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            binary_image = vectorize_image(image_path)\n",
    "            result_dict[filename] = binary_image\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fc70f44-cd1d-415a-b466-a328f8703e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = r'C:\\Users\\damsg\\OGGM\\glacier_geometries_images_small_rotmir'  \n",
    "processed_images = process_folder(folder_path)\n",
    "\n",
    "def resize_array(array, size=(64, 64)):\n",
    "    # Convert the array to PIL Image\n",
    "    image = Image.fromarray(np.array(array, dtype='uint8'))\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size, resample=Image.BILINEAR)\n",
    "    # Convert the resized image back to numpy array\n",
    "    return np.array(resized_image)\n",
    "\n",
    "# Assuming 'data_dict' is your dictionary containing multiple arrays\n",
    "resized_arrays = [resize_array(array) for array in processed_images.values()]\n",
    "\n",
    "# Stack all resized arrays into a single numpy array\n",
    "resized_data_array = np.stack(resized_arrays, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9088a0-f748-44e7-a1fc-6783a1a73358",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9329fa41-c660-4238-b264-f2c93c7ec761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_64 (Conv2D)          (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 650,308\n",
      "Trainable params: 650,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 4 #Change to 2 for form to 4 for Termtype\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=128,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=256,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Dropout(rate=0.60))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a5016afb-f3c6-453c-8457-ce0320d24a51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18568\n",
      "2321\n",
      "18568\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(resized_data_array))\n",
    "print(len(form_vectors_array))\n",
    "y = [form_vectors_array[i] for i in range(len(form_vectors_array)) for _ in range(8)]\n",
    "y1 = [term_vectors_array[i] for i in range(len(term_vectors_array)) for _ in range(8)]\n",
    "\n",
    "print(len(y))\n",
    "print(y[0])\n",
    "X = resized_data_array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size = 0.8, random_state=1)\n",
    "X_train0, X_test0, y_train1, y_test1 = train_test_split(X, y1,train_size = 0.8, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "32fea56e-5747-4a54-8771-8eb719d0960b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- TRAINING ---------\n",
      "465/465 [==============================] - 67s 142ms/step - loss: 1.1678 - categorical_accuracy: 0.6505 - val_loss: 0.8387 - val_categorical_accuracy: 0.8220\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['categorical_accuracy'])\n",
    "print('--------- TRAINING ---------')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x = np.array(X_train0), y = np.array(y_train1),validation_data=(np.array(X_test0), np.array(y_test1)), \n",
    "                    epochs = 1, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56237d1-d317-44a8-9d28-61cc64b4a8e4",
   "metadata": {},
   "source": [
    "## Normal NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9f3d7ec1-f743-425a-907e-c4a6932c1a63",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73111, 68)\n",
      "--------- TRAINING ---------\n",
      "Epoch 1/50\n",
      "1828/1828 [==============================] - 11s 5ms/step - loss: 61.6266 - mean_absolute_error: 61.6266 - val_loss: 55.5240 - val_mean_absolute_error: 55.5240\n",
      "Epoch 2/50\n",
      "1828/1828 [==============================] - 9s 5ms/step - loss: 53.0985 - mean_absolute_error: 53.0985 - val_loss: 50.7720 - val_mean_absolute_error: 50.7720\n",
      "Epoch 3/50\n",
      "1828/1828 [==============================] - 9s 5ms/step - loss: 51.4672 - mean_absolute_error: 51.4672 - val_loss: 52.4324 - val_mean_absolute_error: 52.4324\n",
      "Epoch 4/50\n",
      "1828/1828 [==============================] - 21s 11ms/step - loss: 50.0177 - mean_absolute_error: 50.0177 - val_loss: 48.1875 - val_mean_absolute_error: 48.1875\n",
      "Epoch 5/50\n",
      "1828/1828 [==============================] - 3144s 2s/step - loss: 48.8685 - mean_absolute_error: 48.8685 - val_loss: 47.4212 - val_mean_absolute_error: 47.4212\n",
      "Epoch 6/50\n",
      "1828/1828 [==============================] - 29s 16ms/step - loss: 48.0633 - mean_absolute_error: 48.0633 - val_loss: 46.6244 - val_mean_absolute_error: 46.6244\n",
      "Epoch 7/50\n",
      "1828/1828 [==============================] - 30s 16ms/step - loss: 46.9102 - mean_absolute_error: 46.9102 - val_loss: 45.1587 - val_mean_absolute_error: 45.1587\n",
      "Epoch 8/50\n",
      "1828/1828 [==============================] - 20s 11ms/step - loss: 46.2663 - mean_absolute_error: 46.2663 - val_loss: 46.7960 - val_mean_absolute_error: 46.7960\n",
      "Epoch 9/50\n",
      "1828/1828 [==============================] - 11s 6ms/step - loss: 45.4934 - mean_absolute_error: 45.4934 - val_loss: 43.9972 - val_mean_absolute_error: 43.9972\n",
      "Epoch 10/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 44.7148 - mean_absolute_error: 44.7148 - val_loss: 42.9902 - val_mean_absolute_error: 42.9902\n",
      "Epoch 11/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 44.1100 - mean_absolute_error: 44.1100 - val_loss: 45.7623 - val_mean_absolute_error: 45.7623\n",
      "Epoch 12/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 43.3952 - mean_absolute_error: 43.3952 - val_loss: 41.9265 - val_mean_absolute_error: 41.9265\n",
      "Epoch 13/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 42.4436 - mean_absolute_error: 42.4436 - val_loss: 44.3079 - val_mean_absolute_error: 44.3079\n",
      "Epoch 14/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 41.7969 - mean_absolute_error: 41.7969 - val_loss: 42.0299 - val_mean_absolute_error: 42.0299\n",
      "Epoch 15/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 41.4102 - mean_absolute_error: 41.4102 - val_loss: 41.3299 - val_mean_absolute_error: 41.3299\n",
      "Epoch 16/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 40.9990 - mean_absolute_error: 40.9990 - val_loss: 41.1047 - val_mean_absolute_error: 41.1047\n",
      "Epoch 17/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 40.6158 - mean_absolute_error: 40.6158 - val_loss: 39.6127 - val_mean_absolute_error: 39.6127\n",
      "Epoch 18/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 40.3644 - mean_absolute_error: 40.3644 - val_loss: 40.1381 - val_mean_absolute_error: 40.1381\n",
      "Epoch 19/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 39.5882 - mean_absolute_error: 39.5882 - val_loss: 42.7700 - val_mean_absolute_error: 42.7700\n",
      "Epoch 20/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 39.3812 - mean_absolute_error: 39.3812 - val_loss: 39.9641 - val_mean_absolute_error: 39.9641\n",
      "Epoch 21/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 39.1432 - mean_absolute_error: 39.1432 - val_loss: 39.3230 - val_mean_absolute_error: 39.3230\n",
      "Epoch 22/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 38.7698 - mean_absolute_error: 38.7698 - val_loss: 39.8981 - val_mean_absolute_error: 39.8981\n",
      "Epoch 23/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 38.2935 - mean_absolute_error: 38.2935 - val_loss: 41.2356 - val_mean_absolute_error: 41.2356\n",
      "Epoch 24/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 37.9962 - mean_absolute_error: 37.9962 - val_loss: 40.8663 - val_mean_absolute_error: 40.8663\n",
      "Epoch 25/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 37.6941 - mean_absolute_error: 37.6941 - val_loss: 39.9427 - val_mean_absolute_error: 39.9427\n",
      "Epoch 26/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 37.5465 - mean_absolute_error: 37.5465 - val_loss: 37.2779 - val_mean_absolute_error: 37.2779\n",
      "Epoch 27/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 37.0657 - mean_absolute_error: 37.0657 - val_loss: 38.5801 - val_mean_absolute_error: 38.5801\n",
      "Epoch 28/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 36.7431 - mean_absolute_error: 36.7431 - val_loss: 42.1349 - val_mean_absolute_error: 42.1349\n",
      "Epoch 29/50\n",
      "1828/1828 [==============================] - 14s 8ms/step - loss: 36.3726 - mean_absolute_error: 36.3726 - val_loss: 36.9388 - val_mean_absolute_error: 36.9388\n",
      "Epoch 30/50\n",
      "1828/1828 [==============================] - 14s 8ms/step - loss: 36.0921 - mean_absolute_error: 36.0921 - val_loss: 38.0767 - val_mean_absolute_error: 38.0767\n",
      "Epoch 31/50\n",
      "1828/1828 [==============================] - 14s 8ms/step - loss: 35.8711 - mean_absolute_error: 35.8711 - val_loss: 37.5740 - val_mean_absolute_error: 37.5740\n",
      "Epoch 32/50\n",
      "1828/1828 [==============================] - 14s 8ms/step - loss: 35.7064 - mean_absolute_error: 35.7064 - val_loss: 36.8273 - val_mean_absolute_error: 36.8273\n",
      "Epoch 33/50\n",
      "1828/1828 [==============================] - 14s 7ms/step - loss: 35.5879 - mean_absolute_error: 35.5879 - val_loss: 36.9096 - val_mean_absolute_error: 36.9096\n",
      "Epoch 34/50\n",
      "1828/1828 [==============================] - 14s 7ms/step - loss: 35.2495 - mean_absolute_error: 35.2495 - val_loss: 39.3585 - val_mean_absolute_error: 39.3585\n",
      "Epoch 35/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 35.1602 - mean_absolute_error: 35.1602 - val_loss: 36.2947 - val_mean_absolute_error: 36.2947\n",
      "Epoch 36/50\n",
      "1828/1828 [==============================] - 14s 7ms/step - loss: 34.6985 - mean_absolute_error: 34.6985 - val_loss: 36.6403 - val_mean_absolute_error: 36.6403\n",
      "Epoch 37/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 34.6187 - mean_absolute_error: 34.6187 - val_loss: 37.6457 - val_mean_absolute_error: 37.6457\n",
      "Epoch 38/50\n",
      "1828/1828 [==============================] - 14s 7ms/step - loss: 34.3082 - mean_absolute_error: 34.3082 - val_loss: 36.4932 - val_mean_absolute_error: 36.4932\n",
      "Epoch 39/50\n",
      "1828/1828 [==============================] - 14s 7ms/step - loss: 34.0640 - mean_absolute_error: 34.0640 - val_loss: 35.5239 - val_mean_absolute_error: 35.5239\n",
      "Epoch 40/50\n",
      "1828/1828 [==============================] - 14s 7ms/step - loss: 33.8786 - mean_absolute_error: 33.8786 - val_loss: 35.4101 - val_mean_absolute_error: 35.4101\n",
      "Epoch 41/50\n",
      "1828/1828 [==============================] - 14s 7ms/step - loss: 33.7301 - mean_absolute_error: 33.7301 - val_loss: 35.1304 - val_mean_absolute_error: 35.1304\n",
      "Epoch 42/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 33.5312 - mean_absolute_error: 33.5312 - val_loss: 37.2504 - val_mean_absolute_error: 37.2504\n",
      "Epoch 43/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 33.2937 - mean_absolute_error: 33.2937 - val_loss: 34.9297 - val_mean_absolute_error: 34.9297\n",
      "Epoch 44/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 33.2070 - mean_absolute_error: 33.2070 - val_loss: 35.3106 - val_mean_absolute_error: 35.3106\n",
      "Epoch 45/50\n",
      "1828/1828 [==============================] - 11s 6ms/step - loss: 33.0833 - mean_absolute_error: 33.0833 - val_loss: 34.7490 - val_mean_absolute_error: 34.7490\n",
      "Epoch 46/50\n",
      "1828/1828 [==============================] - 11s 6ms/step - loss: 32.7673 - mean_absolute_error: 32.7673 - val_loss: 36.5724 - val_mean_absolute_error: 36.5724\n",
      "Epoch 47/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 32.5751 - mean_absolute_error: 32.5751 - val_loss: 35.9888 - val_mean_absolute_error: 35.9888\n",
      "Epoch 48/50\n",
      "1828/1828 [==============================] - 11s 6ms/step - loss: 32.2626 - mean_absolute_error: 32.2626 - val_loss: 33.9298 - val_mean_absolute_error: 33.9298\n",
      "Epoch 49/50\n",
      "1828/1828 [==============================] - 11s 6ms/step - loss: 32.1664 - mean_absolute_error: 32.1664 - val_loss: 34.5975 - val_mean_absolute_error: 34.5975\n",
      "Epoch 50/50\n",
      "1828/1828 [==============================] - 11s 6ms/step - loss: 32.0819 - mean_absolute_error: 32.0819 - val_loss: 34.3759 - val_mean_absolute_error: 34.3759\n"
     ]
    }
   ],
   "source": [
    "X0 = glathida_rgis.drop(['ith_m','ith_f','THICKNESS','RGIId'],axis=1) \n",
    "# X0 = glathida_rgis.drop(['Form','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "# X0 = glathida_rgis.drop(['TermType','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X0 = pd.DataFrame(scaler.fit_transform(X0.values), columns=X0.columns, index=X0.index)\n",
    "# y0 = glathida_rgis['Form'] \n",
    "# y0 = glathida_rgis['TermType']\n",
    "y0 = glathida_rgis['THICKNESS'] \n",
    "\n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X0, y0,train_size = 0.8, random_state=1)\n",
    "print(np.shape(X0))\n",
    "model0 = Sequential([\n",
    "    Dense(72,activation='LeakyReLU'   ,name='input_layer'),\n",
    "    Dense(135,activation='relu'   ,name='hidden_layer1'),\n",
    "    Dense(165,activation='relu'   ,name='hidden_layer2'),\n",
    "    Dense(56,activation='relu'   ,name='hidden_layer3'),\n",
    "    Dense(1, name='output')])\n",
    "\n",
    "model0.compile(loss='mean_absolute_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['mean_absolute_error'])\n",
    "\n",
    "print('--------- TRAINING ---------')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model0.fit(x = np.array(X_train0), y = np.array(y_train0),validation_data=(np.array(X_test0), np.array(y_test0)), \n",
    "                    epochs = 50, callbacks=[early_stopping]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "01d9edbe-ef49-44c0-8bc1-51ed32132f3c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1828/1828 [==============================] - 9s 5ms/step - loss: 31.1957 - mean_absolute_error: 31.1957 - val_loss: 33.1355 - val_mean_absolute_error: 33.1355\n",
      "Epoch 2/50\n",
      "1828/1828 [==============================] - 9s 5ms/step - loss: 31.0828 - mean_absolute_error: 31.0828 - val_loss: 33.4525 - val_mean_absolute_error: 33.4525\n",
      "Epoch 3/50\n",
      "1828/1828 [==============================] - 9s 5ms/step - loss: 30.9928 - mean_absolute_error: 30.9928 - val_loss: 32.8045 - val_mean_absolute_error: 32.8045\n",
      "Epoch 4/50\n",
      "1828/1828 [==============================] - 9s 5ms/step - loss: 30.6535 - mean_absolute_error: 30.6535 - val_loss: 33.1943 - val_mean_absolute_error: 33.1943\n",
      "Epoch 5/50\n",
      "1828/1828 [==============================] - 10s 6ms/step - loss: 30.5919 - mean_absolute_error: 30.5919 - val_loss: 32.6486 - val_mean_absolute_error: 32.6486\n",
      "Epoch 6/50\n",
      "1828/1828 [==============================] - 12s 6ms/step - loss: 30.2619 - mean_absolute_error: 30.2619 - val_loss: 33.3583 - val_mean_absolute_error: 33.3583\n",
      "Epoch 7/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 30.3619 - mean_absolute_error: 30.3619 - val_loss: 32.7356 - val_mean_absolute_error: 32.7356\n",
      "Epoch 8/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 30.2302 - mean_absolute_error: 30.2302 - val_loss: 34.3087 - val_mean_absolute_error: 34.3087\n",
      "Epoch 9/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 30.1429 - mean_absolute_error: 30.1429 - val_loss: 31.5595 - val_mean_absolute_error: 31.5595\n",
      "Epoch 10/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 29.8888 - mean_absolute_error: 29.8888 - val_loss: 32.3951 - val_mean_absolute_error: 32.3951\n",
      "Epoch 11/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 29.8011 - mean_absolute_error: 29.8011 - val_loss: 33.4873 - val_mean_absolute_error: 33.4873\n",
      "Epoch 12/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 29.7808 - mean_absolute_error: 29.7808 - val_loss: 33.8412 - val_mean_absolute_error: 33.8412\n",
      "Epoch 13/50\n",
      "1828/1828 [==============================] - 13s 7ms/step - loss: 29.4617 - mean_absolute_error: 29.4617 - val_loss: 32.7663 - val_mean_absolute_error: 32.7663\n",
      "Epoch 14/50\n",
      "1828/1828 [==============================] - 12s 7ms/step - loss: 29.3939 - mean_absolute_error: 29.3939 - val_loss: 32.6177 - val_mean_absolute_error: 32.6177\n"
     ]
    }
   ],
   "source": [
    "history = model0.fit(x = np.array(X_train0), y = np.array(y_train0),validation_data=(np.array(X_test0), np.array(y_test0)), \n",
    "                    epochs = 50, callbacks=[early_stopping]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a238a331-1705-433c-b164-f9b6468e603e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Zmed: 0.005709929073745945\n",
      "2. Aspect: 0.004124656653926662\n",
      "3. Form: 0.0032511009947928217\n",
      "4. POINT_LAT: 0.0028006188892364613\n",
      "5. RGI: 0.0015365256226289703\n",
      "6. aspect_gfa: 0.0013626384053841202\n",
      "7. aspect_300: 0.0010358497998848803\n",
      "8. Zmax: 0.00052399357424735\n",
      "9. smb: 0.0003666735084903561\n",
      "10. aspect_50: 0.00034876667908219084\n",
      "11. slope_lon_gf100: 0.00027349420798070676\n",
      "12. curv_300: 0.0002556475910718836\n",
      "13. slope_lon_gf300: 0.00022655289792580246\n",
      "14. dist_from_border_km_geom: 0.00018556618321193818\n",
      "15. slope_lon_gf450: 0.00015092586798735042\n",
      "16. slope_lat: 0.00010904609561013245\n",
      "17. vy_gf150: 0.00010066974887859014\n",
      "18. vx_gf150: 5.431998820853989e-05\n",
      "19. vx_gf300: 2.8750925930309813e-05\n",
      "20. curv_50: 2.5984332648920637e-05\n",
      "21. vy: 1.5212649709073211e-05\n",
      "22. vy_gf300: 1.2787207047448845e-05\n",
      "23. vy_gf100: 1.0764569195886864e-05\n",
      "24. vx_gfa: 3.74171580541649e-06\n",
      "25. vy_gf50: -1.527155426273019e-06\n",
      "26. dvx_dy: -3.333697056728813e-06\n",
      "27. dvy_dy: -8.650500142592943e-06\n",
      "28. dvy_dx: -1.2245427151635901e-05\n",
      "29. dvx_dx: -1.94867799252596e-05\n",
      "30. vx_gf50: -2.879515504654595e-05\n",
      "31. slope_lon: -2.953081705719951e-05\n",
      "32. vx_gf450: -3.111862729784365e-05\n",
      "33. vx: -4.066022293505167e-05\n",
      "34. vx_gf100: -4.5916789129529786e-05\n",
      "35. vy_gfa: -4.977516776323298e-05\n",
      "36. vy_gf450: -5.263788961068494e-05\n",
      "37. slope_lon_gf50: -7.352727193635778e-05\n",
      "38. curv_gfa: -9.014246897559586e-05\n",
      "39. slope_lat_gf150: -9.13107645754585e-05\n",
      "40. slope_lon_gfa: -0.00012600511830950233\n",
      "41. slope_lon_gf150: -0.00030718408019836385\n",
      "42. slope_lat_gf450: -0.00034425374863172875\n",
      "43. dmdtda_hugo: -0.00037978265949717427\n",
      "44. slope_lat_gf100: -0.00039420699730773333\n",
      "45. slope_lat_gfa: -0.00041090299455541767\n",
      "46. slope_lat_gf50: -0.0005488607635729115\n",
      "47. POINT_LON: -0.0006902447777461296\n",
      "48. slope_lat_gf300: -0.0007446552347615487\n",
      "49. Lmax: -0.0007498592138790227\n",
      "50. Area: -0.0010190315329951737\n",
      "51. Slope: -0.0015997448437967243\n",
      "52. elevation: -0.003058483017767144\n",
      "53. Zmin: -0.004330756908253608\n"
     ]
    }
   ],
   "source": [
    "# perm_importance = permutation_importance(model0, X_test0, y_test0, scoring ='neg_mean_absolute_error', n_repeats=5, random_state=42)\n",
    "\n",
    "feature_importance_scores = perm_importance.importances_mean\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X0.columns  # Assuming X is a pandas DataFrame with feature names\n",
    "\n",
    "# Print or visualize feature importance\n",
    "sorted_feature_indices = feature_importance_scores.argsort()[::-1]\n",
    "sorted_feature_names = feature_names[sorted_feature_indices]\n",
    "\n",
    "for i, feature_name in enumerate(sorted_feature_names):\n",
    "    print(f\"{i+1}. {feature_name}: {feature_importance_scores[sorted_feature_indices[i]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4b6f9-0901-46c0-b68f-487c7904789e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine CNN with NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa71172-485d-4581-9396-972cd97f5251",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Form CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d52eae9f-3974-417e-a4b3-d3764cb8bf49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 62, 62, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 31, 31, 32)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 29, 29, 64)   18496       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 12, 12, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 128)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 4, 4, 256)    295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 256)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1024)         0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           65600       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 67)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 131)          0           ['dense[0][0]',                  \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 131)          17292       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 180)          23760       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           5792        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            33          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 500,317\n",
      "Trainable params: 500,317\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "num_features = 67 #Features in dataset\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 RGB images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(64 + num_features, activation='relu')(combined_input)\n",
    "fc2 = Dense(180, activation='relu')(fc1)\n",
    "fc3 = Dense(180, activation='relu')(fc2)\n",
    "fc3 = Dense(32, activation='relu')(fc2)\n",
    "output = Dense(1, activation='sigmoid')(fc3)  # Output layer for binary classification\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "combined_model.summary()\n",
    "\n",
    "\n",
    "# history = combined_model.fit(inputs = [resized_data_array,]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd00a871-ca2c-4017-baf5-ab4dab898fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = r'C:\\Users\\damsg\\OGGM\\glacier_geometries_images_small'  \n",
    "processed_images = process_folder(folder_path)\n",
    "\n",
    "def resize_array(array, size=(64, 64)):\n",
    "    # Convert the array to PIL Image\n",
    "    image = Image.fromarray(np.array(array, dtype='uint8'))\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size, resample=Image.BILINEAR)\n",
    "    # Convert the resized image back to numpy array\n",
    "    return np.array(resized_image)\n",
    "\n",
    "# Assuming 'data_dict' is your dictionary containing multiple arrays\n",
    "resized_arrays = [resize_array(array) for array in processed_images.values()]\n",
    "\n",
    "# Stack all resized arrays into a single numpy array\n",
    "resized_data_array = np.stack(resized_arrays, axis=0)\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_forms['Form_Vector'] = unique_forms['Form'].apply(convert_to_2d_vector)\n",
    "form_vectors_array = np.array(unique_forms['Form_Vector'].tolist())\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "unique_term['Term_Vector'] = unique_term['TermType'].apply(convert_to_4d_vector)\n",
    "term_vectors_array = np.array(unique_term['Term_Vector'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da67738b-7975-42c1-907f-13977435dec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73111, 64, 64)\n",
      "(73111,)\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'C:\\Users\\damsg\\OGGM\\glacier_geometries_images_small'  \n",
    "processed_images = process_folder(folder_path)\n",
    "\n",
    "# n0_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\n",
    "# metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\n",
    "\n",
    "def resize_array(array, size=(64, 64)):\n",
    "    # Convert the array to PIL Image\n",
    "    image = Image.fromarray(np.array(array, dtype='uint8'))\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size, resample=Image.BILINEAR)\n",
    "    return np.array(resized_image)\n",
    "\n",
    "resized_arrays = [resize_array(array) for array in processed_images.values()]\n",
    "\n",
    "# Stack all resized arrays into a single numpy array\n",
    "resized_data_array = np.stack(resized_arrays, axis=0)\n",
    "\n",
    "pictures = []\n",
    "current_rgi_id = None\n",
    "i = -1  # Initial value of i\n",
    "\n",
    "for rgi_id in glathida_rgis['RGIId']:\n",
    "    if rgi_id != current_rgi_id:\n",
    "        i += 1  # Increment i when RGIId changes\n",
    "        current_rgi_id = rgi_id\n",
    "    pictures.append(resized_data_array[i])\n",
    "\n",
    "# Convert pictures to a numpy array if needed\n",
    "pictures = np.array(pictures)\n",
    "print(np.shape(pictures))\n",
    "print(np.shape(glathida_rgis['RGIId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f943d7f9-60b6-4614-b7b8-44cf14c02585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2321\n",
      "2101\n",
      "2321\n",
      "CPU times: total: 1min 26s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the metadata files\n",
    "metadata19 = pd.read_csv('metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv')\n",
    "n0_metadata19 = pd.read_csv('n0_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv')\n",
    "\n",
    "# Get the list of RGIId from both metadata files\n",
    "metadata19_rgi_ids = metadata19['RGIId'].tolist()\n",
    "n0_rgi_ids = n0_metadata19['RGIId'].tolist()\n",
    "metadata19_rgi_ids = np.unique(metadata19_rgi_ids)\n",
    "# Assuming images are in the same order as metadata19\n",
    "images = resized_data_array\n",
    "print(len(np.unique(metadata19_rgi_ids)))\n",
    "print(len(np.unique(n0_metadata19['RGIId'])))\n",
    "print(len(resized_data_array))\n",
    "\n",
    "pictures = []\n",
    "ind = 0\n",
    "for i in range(len(metadata19_rgi_ids)):\n",
    "    for j in range(len(n0_rgi_ids)):\n",
    "        if metadata19_rgi_ids[i] == n0_rgi_ids[j]:\n",
    "            pictures.append(images[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9454b251-2f2f-452d-8e58-e1d28dd491c3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73111, 68)\n",
      "Epoch 1/7\n",
      "  15/1828 [..............................] - ETA: 4:14 - loss: 0.5811 - accuracy: 0.7312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 48\u001b[0m\n\u001b[0;32m     36\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m     37\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Metric to monitor\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,          \u001b[38;5;66;03m# Number of epochs with no improvement after which training will be stopped\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Restore the weights of the best epoch\u001b[39;00m\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     41\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Form_model_weights_n0.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Full file path to save the model weights\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,               \u001b[38;5;66;03m# Metric to monitor\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,              \u001b[38;5;66;03m# Save only the best weights\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m            \u001b[38;5;66;03m# Save only the weights (not the entire model)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m )\n\u001b[1;32m---> 48\u001b[0m \u001b[43mcombined_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpictures_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX01_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Inputs: list of image data and non-image data\u001b[39;49;00m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43my01_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Target labels\u001b[39;49;00m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Batch size\u001b[39;49;00m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpictures_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX01_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my01_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Validation data\u001b[39;49;00m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Include the early stopping callback\u001b[39;49;00m\n\u001b[0;32m     55\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m combined_model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Form_model_weights_final_n0.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pictures = resized_data_array\n",
    "pictures = np.array(pictures)\n",
    "\n",
    "y01 = glathida_rgis['Form'] \n",
    "y02_values = glathida_rgis['TermType']\n",
    "\n",
    "y02 = np.array([convert_to_4d_vector(term_value) for term_value in y02_values])\n",
    "# y02_one_hot = [convert_to_4d_vector(term_value) for term_value in y02_values]\n",
    "\n",
    "# Convert the list to a numpy array if needed\n",
    "# y02 = np.array(y02_one_hot)\n",
    "\n",
    "\n",
    "y03 = glathida_rgis['THICKNESS']\n",
    "\n",
    "X01 = glathida_rgis.drop(['Form','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "X02 = glathida_rgis.drop(['TermType','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "X03 = glathida_rgis.drop(['RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "print(np.shape(X03))\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X01 = pd.DataFrame(scaler.fit_transform(X01.values), columns=X01.columns, index=X01.index)\n",
    "X02 = pd.DataFrame(scaler.fit_transform(X02.values), columns=X02.columns, index=X02.index)\n",
    "X03 = pd.DataFrame(scaler.fit_transform(X03.values), columns=X03.columns, index=X03.index)\n",
    "\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "\n",
    "X01_train, X01_test, y01_train, y01_test = train_test_split(X01, y01,train_size = 0.8, random_state=42)\n",
    "X02_train, X02_test, y02_train, y02_test = train_test_split(X02, y02,train_size = 0.8, random_state=42)\n",
    "X03_train, X03_test, y03_train, y03_test = train_test_split(X03, y03,train_size = 0.8, random_state=42)\n",
    "#Shooting for form\n",
    "pictures_train, pictures_val, X01_train, X01_val, y01_train, y01_val = train_test_split(\n",
    "    pictures, X01, y01, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=2,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Form_model_weights_n0.h5',  # Full file path to save the model weights\n",
    "    monitor='val_loss',               # Metric to monitor\n",
    "    save_best_only=True,              # Save only the best weights\n",
    "    save_weights_only=True            # Save only the weights (not the entire model)\n",
    ")\n",
    "\n",
    "combined_model.fit(\n",
    "    [pictures_train, X01_train],  # Inputs: list of image data and non-image data\n",
    "    y01_train,                    # Target labels\n",
    "    epochs=7,                    # Number of epochs\n",
    "    batch_size=32,                # Batch size\n",
    "    validation_data=([pictures_val, X01_val], y01_val),  # Validation data\n",
    "    callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    ")\n",
    "combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Form_model_weights_final_n0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc163ead-10e3-4c47-bbbc-de888c537be6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Termtype CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "591ac37d-6e88-49da-b6c4-1dade1613f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 62, 62, 32)   320         ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_20 (MaxPooling2D  (None, 31, 31, 32)  0           ['conv2d_20[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 29, 29, 64)   18496       ['max_pooling2d_20[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_21 (MaxPooling2D  (None, 14, 14, 64)  0           ['conv2d_21[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 12, 12, 128)  73856       ['max_pooling2d_21[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooling2D  (None, 6, 6, 128)   0           ['conv2d_22[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 4, 4, 256)    295168      ['max_pooling2d_22[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooling2D  (None, 2, 2, 256)   0           ['conv2d_23[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 1024)         0           ['max_pooling2d_23[0][0]']       \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 64)           65600       ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 68)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 132)          0           ['dense_30[0][0]',               \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 132)          17556       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 200)          26600       ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 32)           6432        ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 4)            132         ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 504,160\n",
      "Trainable params: 504,160\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "num_features = 68 #Features in dataset\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 Greyscale images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(64 + num_features, activation='relu')(combined_input)\n",
    "fc2 = Dense(200, activation='relu')(fc1)\n",
    "fc3 = Dense(220, activation='relu')(fc2)\n",
    "fc3 = Dense(32, activation='relu')(fc2)\n",
    "output = Dense(4, activation='sigmoid')(fc3)  # Output layer for multi classification\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "combined_model.summary()\n",
    "\n",
    "\n",
    "# history = combined_model.fit(inputs = [resized_data_array,]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c89c58d6-ab5c-426b-b974-a276eb41c83a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "2033/2033 [==============================] - 317s 155ms/step - loss: 0.1012 - accuracy: 0.9629 - val_loss: 0.0768 - val_accuracy: 0.9705\n",
      "Epoch 2/7\n",
      "2033/2033 [==============================] - 317s 156ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0455 - val_accuracy: 0.9814\n",
      "Epoch 3/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 4/7\n",
      "2033/2033 [==============================] - 324s 159ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 1.8127e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0138 - val_accuracy: 0.9945\n",
      "Epoch 6/7\n",
      "2033/2033 [==============================] - 317s 156ms/step - loss: 2.5115e-04 - accuracy: 0.9999 - val_loss: 2.7377e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 1.5606e-06 - accuracy: 1.0000 - val_loss: 7.9302e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Shooting for TermType\n",
    "pictures_train, pictures_val, X02_train, X02_val, y02_train, y02_val = train_test_split(\n",
    "    pictures, X02, y02, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=3,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Term_model_weights_n0.h5',  # Full file path to save the model weights\n",
    "    monitor='val_loss',               # Metric to monitor\n",
    "    save_best_only=True,              # Save only the best weights\n",
    "    save_weights_only=True            # Save only the weights (not the entire model)\n",
    ")\n",
    "# Train the model with early stopping\n",
    "combined_model.fit(\n",
    "    [pictures_train, X02_train],  # Inputs: list of image data and non-image data\n",
    "    y02_train,                    # Target labels\n",
    "    epochs=7,                    # Number of epochs\n",
    "    batch_size=32,                # Batch size\n",
    "    validation_data=([pictures_val, X02_val], y02_val),  # Validation data\n",
    "    callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    ")\n",
    "\n",
    "combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Term_model_weights_final_n0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f8a2a-a28b-47c4-acc6-977872f62bf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Thickness CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "222a0150-44d7-4abd-ace0-64607c832f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73111, 72)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)          [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 62, 62, 32)   320         ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_60 (MaxPooling2D  (None, 31, 31, 32)  0           ['conv2d_60[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 29, 29, 64)   18496       ['max_pooling2d_60[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_61 (MaxPooling2D  (None, 14, 14, 64)  0           ['conv2d_61[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 12, 12, 128)  73856       ['max_pooling2d_61[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_62 (MaxPooling2D  (None, 6, 6, 128)   0           ['conv2d_62[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 4, 4, 256)    295168      ['max_pooling2d_62[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_63 (MaxPooling2D  (None, 2, 2, 256)   0           ['conv2d_63[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 1024)         0           ['max_pooling2d_63[0][0]']       \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 64)           65600       ['flatten_15[0][0]']             \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 68)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 132)          0           ['dense_30[0][0]',               \n",
      "                                                                  'input_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 132)          17556       ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 145)          19285       ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 96)           14016       ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 1)            97          ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 504,394\n",
      "Trainable params: 504,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_features = 68 #Features in dataset\n",
    "print(np.shape(glathida_rgis))\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 RGB images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(64 + num_features, activation='relu')(combined_input)\n",
    "fc2 = Dense(145, activation='relu')(fc1)\n",
    "fc3 = Dense(175, activation='relu')(fc2)\n",
    "fc3 = Dense(96, activation='relu')(fc2)\n",
    "output = Dense(1)(fc3)  # Output layer for regression\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam',loss= 'mean_absolute_error',metrics=['mean_absolute_error'])\n",
    "# Print the model summary\n",
    "combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "c2f08837-7c87-4d21-8a53-fa81bf4c054c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1828/1828 [==============================] - 167s 92ms/step - loss: 24.7428 - mean_absolute_error: 24.7428 - val_loss: 28.5411 - val_mean_absolute_error: 28.5411\n",
      "Epoch 2/50\n",
      "1828/1828 [==============================] - 171s 94ms/step - loss: 24.6220 - mean_absolute_error: 24.6220 - val_loss: 29.1104 - val_mean_absolute_error: 29.1104\n",
      "Epoch 3/50\n",
      "1828/1828 [==============================] - 169s 92ms/step - loss: 24.5900 - mean_absolute_error: 24.5900 - val_loss: 28.4432 - val_mean_absolute_error: 28.4432\n",
      "Epoch 4/50\n",
      "1828/1828 [==============================] - 170s 93ms/step - loss: 24.6215 - mean_absolute_error: 24.6215 - val_loss: 29.5817 - val_mean_absolute_error: 29.5817\n",
      "Epoch 5/50\n",
      "1828/1828 [==============================] - 162s 89ms/step - loss: 24.4717 - mean_absolute_error: 24.4717 - val_loss: 27.7941 - val_mean_absolute_error: 27.7941\n",
      "Epoch 6/50\n",
      "1828/1828 [==============================] - 164s 89ms/step - loss: 24.3767 - mean_absolute_error: 24.3767 - val_loss: 28.9186 - val_mean_absolute_error: 28.9186\n",
      "Epoch 7/50\n",
      "1828/1828 [==============================] - 168s 92ms/step - loss: 24.2477 - mean_absolute_error: 24.2477 - val_loss: 28.3189 - val_mean_absolute_error: 28.3189\n",
      "Epoch 8/50\n",
      "1828/1828 [==============================] - 171s 93ms/step - loss: 24.1750 - mean_absolute_error: 24.1750 - val_loss: 27.9665 - val_mean_absolute_error: 27.9665\n",
      "Epoch 9/50\n",
      "1828/1828 [==============================] - 176s 96ms/step - loss: 24.0952 - mean_absolute_error: 24.0952 - val_loss: 28.2541 - val_mean_absolute_error: 28.2541\n",
      "Epoch 10/50\n",
      "1828/1828 [==============================] - 179s 98ms/step - loss: 24.0363 - mean_absolute_error: 24.0363 - val_loss: 27.5709 - val_mean_absolute_error: 27.5709\n",
      "Epoch 11/50\n",
      "1828/1828 [==============================] - 178s 97ms/step - loss: 24.0260 - mean_absolute_error: 24.0260 - val_loss: 28.1467 - val_mean_absolute_error: 28.1467\n",
      "Epoch 12/50\n",
      "1828/1828 [==============================] - 181s 99ms/step - loss: 23.9375 - mean_absolute_error: 23.9375 - val_loss: 27.9965 - val_mean_absolute_error: 27.9965\n",
      "Epoch 13/50\n",
      "1828/1828 [==============================] - 189s 103ms/step - loss: 23.8120 - mean_absolute_error: 23.8120 - val_loss: 27.7376 - val_mean_absolute_error: 27.7376\n",
      "Epoch 14/50\n",
      "1828/1828 [==============================] - 197s 108ms/step - loss: 23.7191 - mean_absolute_error: 23.7191 - val_loss: 27.7881 - val_mean_absolute_error: 27.7881\n",
      "Epoch 15/50\n",
      "1828/1828 [==============================] - 201s 110ms/step - loss: 23.7724 - mean_absolute_error: 23.7724 - val_loss: 28.1746 - val_mean_absolute_error: 28.1746\n",
      "Epoch 16/50\n",
      "1828/1828 [==============================] - 197s 108ms/step - loss: 23.7980 - mean_absolute_error: 23.7980 - val_loss: 27.6943 - val_mean_absolute_error: 27.6943\n",
      "Epoch 17/50\n",
      "1828/1828 [==============================] - 198s 108ms/step - loss: 23.5880 - mean_absolute_error: 23.5880 - val_loss: 27.9306 - val_mean_absolute_error: 27.9306\n",
      "Epoch 18/50\n",
      "1828/1828 [==============================] - 195s 107ms/step - loss: 23.6071 - mean_absolute_error: 23.6071 - val_loss: 27.2646 - val_mean_absolute_error: 27.2646\n",
      "Epoch 19/50\n",
      "1828/1828 [==============================] - 198s 109ms/step - loss: 23.5487 - mean_absolute_error: 23.5487 - val_loss: 27.5061 - val_mean_absolute_error: 27.5061\n",
      "Epoch 20/50\n",
      "1828/1828 [==============================] - 200s 110ms/step - loss: 23.4552 - mean_absolute_error: 23.4552 - val_loss: 28.4979 - val_mean_absolute_error: 28.4979\n",
      "Epoch 21/50\n",
      "1828/1828 [==============================] - 194s 106ms/step - loss: 23.4600 - mean_absolute_error: 23.4600 - val_loss: 27.3773 - val_mean_absolute_error: 27.3773\n",
      "Epoch 22/50\n",
      "1828/1828 [==============================] - 199s 109ms/step - loss: 23.3641 - mean_absolute_error: 23.3641 - val_loss: 27.5278 - val_mean_absolute_error: 27.5278\n",
      "Epoch 23/50\n",
      "1828/1828 [==============================] - 211s 115ms/step - loss: 23.2209 - mean_absolute_error: 23.2209 - val_loss: 27.3894 - val_mean_absolute_error: 27.3894\n",
      "Epoch 24/50\n",
      "1828/1828 [==============================] - 211s 116ms/step - loss: 23.2948 - mean_absolute_error: 23.2948 - val_loss: 27.3066 - val_mean_absolute_error: 27.3066\n",
      "Epoch 25/50\n",
      "1828/1828 [==============================] - 199s 109ms/step - loss: 23.1613 - mean_absolute_error: 23.1613 - val_loss: 27.8400 - val_mean_absolute_error: 27.8400\n",
      "Epoch 26/50\n",
      "1828/1828 [==============================] - 203s 111ms/step - loss: 23.0717 - mean_absolute_error: 23.0717 - val_loss: 27.9739 - val_mean_absolute_error: 27.9739\n"
     ]
    }
   ],
   "source": [
    "#Shooting for Thickness\n",
    "pictures_train, pictures_val, X03_train, X03_val, y03_train, y03_val = train_test_split(\n",
    "    pictures, X03, y03, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=8,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Thick_model_weights_n0.h5',  # Full file path to save the model weights\n",
    "    monitor='val_loss',               # Metric to monitor\n",
    "    save_best_only=True,              # Save only the best weights\n",
    "    save_weights_only=True            # Save only the weights (not the entire model)\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "combined_model.fit(\n",
    "    [pictures_train, X03_train],  # Inputs: list of image data and non-image data\n",
    "    y03_train,                    # Target labels\n",
    "    epochs=50,                   # Number of epochs\n",
    "    batch_size=32,                # Batch size\n",
    "    validation_data=([pictures_val, X03_val], y03_val),  # Validation data\n",
    "    callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    ")\n",
    "\n",
    "combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Thick_model_weights_final_n0.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "5e81629d-b017-4334-8e59-b23a91b15e79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200.3994  ]\n",
      " [221.37292 ]\n",
      " [177.01059 ]\n",
      " ...\n",
      " [ 77.300995]\n",
      " [ 35.623062]\n",
      " [315.00327 ]]\n",
      "14623\n"
     ]
    }
   ],
   "source": [
    "# y_preds = combined_model.predict([pictures_val, X03_val])\n",
    "# evaluation_plot(combined_model,y03_val, y_preds)\n",
    "print(y_preds)\n",
    "print(len(y03_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08980733-94a1-4462-8611-51c56cf06792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluation_plot1(model,pictures , X_test, y_test):\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict([pictures, X03_val])\n",
    "    \n",
    "    # Flatten the predictions if needed\n",
    "    if len(y_pred.shape) > 1 and y_pred.shape[1] == 1:\n",
    "        y_pred = y_pred.flatten()\n",
    "        \n",
    "    # Convert y_test to numpy array\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Calculate residuals and relative errors\n",
    "    residuals = y_test - y_pred\n",
    "    relative_errors = residuals / np.abs(y_test)\n",
    "    relative_errors = relative_errors[np.abs(relative_errors) <= 1.5]\n",
    "    percentile_90 = np.percentile(np.abs(residuals), 90)\n",
    "    high_residual_mask = np.abs(residuals) <= percentile_90\n",
    "    \n",
    "    # Plot the Distribution of the Residuals and the Relative Errors\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "    ax1.hist(residuals, bins=100)\n",
    "    ax1.set_title('Distribution of Residuals')\n",
    "    ax1.set_xlabel('Residuals')\n",
    "    ax1.set_ylabel('Count')\n",
    "    \n",
    "    ax2.hist(relative_errors, bins='auto')\n",
    "    ax2.set_title('Distribution of Relative Errors')\n",
    "    ax2.set_xlabel('Relative Prediction Error')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_xlim(-1.5, 1.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the Diversion\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, c='blue', alpha=0.1, label='100th percentile')\n",
    "    plt.scatter(y_test[high_residual_mask], y_pred[high_residual_mask], c='green', alpha=0.1, label='residual <= 90th percentile')\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='orange', linewidth=2)\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.title('Diversion')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Usage example:\n",
    "# Assuming you have a trained model and test data (X_test, y_test)\n",
    "# model = ... # Your trained TensorFlow/Keras model\n",
    "# X_test, y_test = ... # Your test data\n",
    "\n",
    "evaluation_plot1(combined_model,pictures_val, X03_val, y03_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc8c80-7b08-4696-bf95-5640edc122f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_model.load_weights('r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/model_weights_final.h5'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89615cf3-7923-4431-bc40-bf59df44a95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(np.shape(pictures))\n",
    "# print(np.shape(glathida_rgis))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d1c42-d9e7-44ec-b55d-7d133ee6592c",
   "metadata": {},
   "source": [
    "## LIGHTGBM + CNN\n",
    "### (For Luisa) Change LGBM to XGB here :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "424d1ae1-c67d-46d4-9eda-6109e8cf7c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,840\n",
      "Trainable params: 387,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1828/1828 [==============================] - 25s 14ms/step\n",
      "457/457 [==============================] - 6s 14ms/step\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.497062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 243838\n",
      "[LightGBM] [Info] Number of data points in the train set: 58488, number of used features: 1086\n",
      "[LightGBM] [Info] Start training from score 152.060987\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4030]\ttraining's l1: 3.02104\tvalid_1's l1: 19.3031\n",
      "Mean Absolute Error on validation set: 19.303063625529806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "pictures_train, pictures_val, X03_train, X03_val, y03_train, y03_val = train_test_split(\n",
    "    pictures, X03, y03, test_size=0.2, random_state=42)\n",
    "\n",
    "num_features = X03.shape[1]  # Number of non-image features\n",
    "\n",
    "# Define the CNN model for feature extraction\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 grayscale images\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Define the model to output the flattened features\n",
    "feature_extraction_model = Model(inputs=image_input, outputs=flatten)\n",
    "feature_extraction_model.summary()\n",
    "\n",
    "# Extract features from the training and validation image data\n",
    "image_features_train = feature_extraction_model.predict(pictures_train)\n",
    "image_features_val = feature_extraction_model.predict(pictures_val)\n",
    "\n",
    "# Combine image features with non-image data\n",
    "combined_train_data = np.concatenate([image_features_train, X03_train], axis=1)\n",
    "combined_val_data = np.concatenate([image_features_val, X03_val], axis=1)\n",
    "\n",
    "# Create LightGBM datasets for training and validation\n",
    "train_data = lgb.Dataset(combined_train_data, label=y03_train)\n",
    "val_data = lgb.Dataset(combined_val_data, label=y03_val, reference=train_data)\n",
    "\n",
    "# Define LightGBM parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 64,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Train the LightGBM model with early stopping\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    callbacks=[early_stopping(stopping_rounds=5)]\n",
    ")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions_val = gbm.predict(combined_val_data)\n",
    "\n",
    "# Evaluate the model (example: Mean Absolute Error)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = mean_absolute_error(y03_val, predictions_val)\n",
    "print(f'Mean Absolute Error on validation set: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b75890bf-ceb1-486d-9847-297e93082c9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 64, 64, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_80 (MaxPoolin  (None, 31, 31, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPoolin  (None, 6, 6, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_83 (MaxPoolin  (None, 2, 2, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,840\n",
      "Trainable params: 387,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1828/1828 [==============================] - 23s 13ms/step\n",
      "457/457 [==============================] - 8s 18ms/step\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.543804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 236237\n",
      "[LightGBM] [Info] Number of data points in the train set: 58488, number of used features: 1078\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Start training from score 152.060987\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "Mean Absolute Error on validation set: 20.015948070205962\n",
      "2285/2285 [==============================] - 50s 22ms/step\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.628316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 231765\n",
      "[LightGBM] [Info] Number of data points in the train set: 58488, number of used features: 1077\n",
      "[LightGBM] [Info] Start training from score 167.484607\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.459807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 231022\n",
      "[LightGBM] [Info] Number of data points in the train set: 58489, number of used features: 1076\n",
      "[LightGBM] [Info] Start training from score 130.052558\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 228755\n",
      "[LightGBM] [Info] Number of data points in the train set: 58489, number of used features: 1077\n",
      "[LightGBM] [Info] Start training from score 154.836883\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231500\n",
      "[LightGBM] [Info] Number of data points in the train set: 58489, number of used features: 1079\n",
      "[LightGBM] [Info] Start training from score 158.889982\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 233774\n",
      "[LightGBM] [Info] Number of data points in the train set: 58489, number of used features: 1078\n",
      "[LightGBM] [Info] Start training from score 146.970842\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "Cross-Validation: 57.8456 +- 21.7281\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import lightgbm as lgb\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# from sklearn.model_selection import cross_val_score, train_test_split\n",
    "# from tensorflow.keras import Input, Model, layers\n",
    "\n",
    "# # Split the data into training and validation sets\n",
    "# pictures_train, pictures_val, X03_train, X03_val, y03_train, y03_val = train_test_split(\n",
    "#     pictures, X03, y03, test_size=0.2, random_state=42)\n",
    "\n",
    "# num_features = X03.shape[1]  # Number of non-image features\n",
    "\n",
    "# # Define the CNN model for feature extraction\n",
    "# image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 grayscale images\n",
    "\n",
    "# conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "# pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "# conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "# pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "# conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "# pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "# conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "# pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "# flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# # Define the model to output the flattened features\n",
    "# feature_extraction_model = Model(inputs=image_input, outputs=flatten)\n",
    "# feature_extraction_model.summary()\n",
    "\n",
    "# # Extract features from the training and validation image data\n",
    "# image_features_train = feature_extraction_model.predict(pictures_train)\n",
    "# image_features_val = feature_extraction_model.predict(pictures_val)\n",
    "\n",
    "# # Combine image features with non-image data\n",
    "# combined_train_data = np.concatenate([image_features_train, X03_train], axis=1)\n",
    "# combined_val_data = np.concatenate([image_features_val, X03_val], axis=1)\n",
    "\n",
    "# # Train the LightGBM model with early stopping\n",
    "# gbm = LGBMRegressor(\n",
    "#     objective='regression',\n",
    "#     metric='mae',\n",
    "#     boosting_type='gbdt',\n",
    "#     num_leaves=31,\n",
    "#     learning_rate=0.05,\n",
    "#     feature_fraction=0.9,\n",
    "#     n_estimators=5000\n",
    "# )\n",
    "\n",
    "# # Fit the model with early stopping on validation data\n",
    "# gbm.fit(\n",
    "#     combined_train_data, y03_train,\n",
    "#     eval_set=[(combined_val_data, y03_val)],\n",
    "#     eval_metric='mae',\n",
    "#     # early_stopping_rounds=5\n",
    "# )\n",
    "\n",
    "# # Make predictions on the validation set\n",
    "# predictions_val = gbm.predict(combined_val_data)\n",
    "\n",
    "# # Evaluate the model (example: Mean Absolute Error)\n",
    "# mae = mean_absolute_error(y03_val, predictions_val)\n",
    "# print(f'Mean Absolute Error on validation set: {mae}')\n",
    "\n",
    "# # Perform cross-validation\n",
    "# combined_data = np.concatenate([feature_extraction_model.predict(pictures), X03], axis=1)\n",
    "# cv_scores = cross_val_score(gbm, combined_data, y03, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# print(\"Cross-Validation: %.4f +- %.4f\" % (-cv_scores.mean(), cv_scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "20c95011-d1e6-4bf4-8da8-bc8223608d66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-94.10028608, -70.40271508, -42.55646754, -34.27147357,\n",
       "       -47.89710485])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(glathida_rgis2['PICTURE'][0][2])\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b812598-007b-4de1-b1ae-57f66f65b7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1828/1828 [==============================] - 26s 14ms/step\n",
      "457/457 [==============================] - 8s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:05:05,998] A new study created in memory with name: no-name-28cf411c-0339-4584-8f0e-77e1a8330c03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 27.4446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:05:35,956] Trial 0 finished with value: 27.444622907870656 and parameters: {'learning_rate': 0.23860463882129201, 'lambda_l1': 68.4695759933995, 'lambda_l2': 44.447449211379244, 'num_leaves': 361, 'feature_fraction': 0.6918461316459736, 'bagging_fraction': 0.7067823099239899, 'bagging_freq': 4, 'min_child_samples': 242}. Best is trial 0 with value: 27.444622907870656.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 26.5006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:06:26,050] Trial 1 finished with value: 26.50059152234435 and parameters: {'learning_rate': 0.07832612929441111, 'lambda_l1': 27.85541026832669, 'lambda_l2': 46.025919335564794, 'num_leaves': 760, 'feature_fraction': 0.7999623674017602, 'bagging_fraction': 0.9083601027410808, 'bagging_freq': 4, 'min_child_samples': 128}. Best is trial 1 with value: 26.50059152234435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 28.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:07:00,430] Trial 2 finished with value: 28.223047383308117 and parameters: {'learning_rate': 0.09802203744141541, 'lambda_l1': 7.413926781466467, 'lambda_l2': 18.469850107338306, 'num_leaves': 326, 'feature_fraction': 0.6967835924915741, 'bagging_fraction': 0.7922197899349528, 'bagging_freq': 4, 'min_child_samples': 226}. Best is trial 1 with value: 26.50059152234435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 35.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:07:49,285] Trial 3 finished with value: 35.5780228502358 and parameters: {'learning_rate': 0.021386583036404398, 'lambda_l1': 59.890092550719466, 'lambda_l2': 4.997771419111741, 'num_leaves': 562, 'feature_fraction': 0.6484251244596111, 'bagging_fraction': 0.9244994376530282, 'bagging_freq': 4, 'min_child_samples': 67}. Best is trial 1 with value: 26.50059152234435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 29.7426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:08:19,184] Trial 4 finished with value: 29.742615178999156 and parameters: {'learning_rate': 0.0744898377808023, 'lambda_l1': 45.871235377708736, 'lambda_l2': 46.198151188376094, 'num_leaves': 749, 'feature_fraction': 0.5845468479466689, 'bagging_fraction': 0.8491644746423879, 'bagging_freq': 3, 'min_child_samples': 248}. Best is trial 1 with value: 26.50059152234435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 27.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:08:56,310] Trial 5 finished with value: 27.91277921072404 and parameters: {'learning_rate': 0.10113702901178889, 'lambda_l1': 99.12197925560132, 'lambda_l2': 46.22754674256812, 'num_leaves': 896, 'feature_fraction': 0.7850676587426187, 'bagging_fraction': 0.9162168201850156, 'bagging_freq': 3, 'min_child_samples': 239}. Best is trial 1 with value: 26.50059152234435.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 22.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:09:51,413] Trial 6 finished with value: 22.86518148583934 and parameters: {'learning_rate': 0.15831346264038001, 'lambda_l1': 42.76235899177288, 'lambda_l2': 19.42120896077825, 'num_leaves': 1010, 'feature_fraction': 0.5198695227730116, 'bagging_fraction': 0.744846204664508, 'bagging_freq': 4, 'min_child_samples': 60}. Best is trial 6 with value: 22.86518148583934.\n",
      "[I 2024-06-08 10:09:58,745] Trial 7 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 27.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:10:33,038] Trial 8 finished with value: 27.02401824145269 and parameters: {'learning_rate': 0.1264570100331825, 'lambda_l1': 62.29359503195974, 'lambda_l2': 38.80286744878923, 'num_leaves': 627, 'feature_fraction': 0.56801453342218, 'bagging_fraction': 0.9740474404408783, 'bagging_freq': 2, 'min_child_samples': 243}. Best is trial 6 with value: 22.86518148583934.\n",
      "[I 2024-06-08 10:10:39,568] Trial 9 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 25.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:11:07,597] Trial 10 finished with value: 25.722519006408227 and parameters: {'learning_rate': 0.17697174244856914, 'lambda_l1': 85.29988105143366, 'lambda_l2': 4.6871417149349845, 'num_leaves': 98, 'feature_fraction': 0.5038881594291217, 'bagging_fraction': 0.7861526668909546, 'bagging_freq': 5, 'min_child_samples': 8}. Best is trial 6 with value: 22.86518148583934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 25.0669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:11:38,502] Trial 11 finished with value: 25.06691065952796 and parameters: {'learning_rate': 0.18167056666740708, 'lambda_l1': 96.50501399134755, 'lambda_l2': 1.709056408069178, 'num_leaves': 112, 'feature_fraction': 0.5044194381140346, 'bagging_fraction': 0.7813613523918097, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 6 with value: 22.86518148583934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 25.8565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:12:06,212] Trial 12 finished with value: 25.856524761828755 and parameters: {'learning_rate': 0.17812385687317536, 'lambda_l1': 39.06077258124343, 'lambda_l2': 30.476519509376516, 'num_leaves': 102, 'feature_fraction': 0.5010179277184263, 'bagging_fraction': 0.7767589422327779, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 6 with value: 22.86518148583934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 23.4008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:13:04,903] Trial 13 finished with value: 23.40080442812189 and parameters: {'learning_rate': 0.16826006953475606, 'lambda_l1': 79.29523942963048, 'lambda_l2': 12.634337100347405, 'num_leaves': 423, 'feature_fraction': 0.5586633602379029, 'bagging_fraction': 0.7112164722103572, 'bagging_freq': 5, 'min_child_samples': 57}. Best is trial 6 with value: 22.86518148583934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 23.6457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:14:00,650] Trial 14 finished with value: 23.645717608226295 and parameters: {'learning_rate': 0.224933217112507, 'lambda_l1': 77.01564085240138, 'lambda_l2': 14.172277487042148, 'num_leaves': 442, 'feature_fraction': 0.5721385207893085, 'bagging_fraction': 0.7018230416181225, 'bagging_freq': 3, 'min_child_samples': 69}. Best is trial 6 with value: 22.86518148583934.\n",
      "[I 2024-06-08 10:14:07,690] Trial 15 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 23.7023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:15:00,028] Trial 16 finished with value: 23.702344860409962 and parameters: {'learning_rate': 0.20351973128886394, 'lambda_l1': 50.01162268662762, 'lambda_l2': 22.33577699061354, 'num_leaves': 480, 'feature_fraction': 0.5432197945453745, 'bagging_fraction': 0.8316886180153507, 'bagging_freq': 4, 'min_child_samples': 94}. Best is trial 6 with value: 22.86518148583934.\n",
      "[I 2024-06-08 10:15:07,644] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-06-08 10:15:15,944] Trial 18 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 23.8126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:16:01,699] Trial 19 finished with value: 23.812611845156265 and parameters: {'learning_rate': 0.2077992206087567, 'lambda_l1': 84.35287348619786, 'lambda_l2': 22.512961414486632, 'num_leaves': 259, 'feature_fraction': 0.5377076783207377, 'bagging_fraction': 0.7507770061717804, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 6 with value: 22.86518148583934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 24.8046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:16:51,267] Trial 20 finished with value: 24.80461257970552 and parameters: {'learning_rate': 0.2498345574701813, 'lambda_l1': 43.405040633843406, 'lambda_l2': 10.428388300495877, 'num_leaves': 453, 'feature_fraction': 0.6078238882964989, 'bagging_fraction': 0.7071171121899786, 'bagging_freq': 5, 'min_child_samples': 97}. Best is trial 6 with value: 22.86518148583934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 24.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:17:45,049] Trial 21 finished with value: 24.011348121333526 and parameters: {'learning_rate': 0.21601934056208846, 'lambda_l1': 72.61247440261718, 'lambda_l2': 15.938470413826595, 'num_leaves': 448, 'feature_fraction': 0.5811436516781793, 'bagging_fraction': 0.7083209279589272, 'bagging_freq': 3, 'min_child_samples': 86}. Best is trial 6 with value: 22.86518148583934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l1: 22.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-08 10:18:53,967] Trial 22 finished with value: 22.899595715305797 and parameters: {'learning_rate': 0.22516091558071272, 'lambda_l1': 87.4147869342442, 'lambda_l2': 12.450083449010126, 'num_leaves': 557, 'feature_fraction': 0.5552647601101932, 'bagging_fraction': 0.7266305334250976, 'bagging_freq': 3, 'min_child_samples': 34}. Best is trial 6 with value: 22.86518148583934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 5 rounds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "pictures_train, pictures_val, X03_train, X03_val, y03_train, y03_val = train_test_split(\n",
    "    pictures, X03, y03, test_size=0.2, random_state=42)\n",
    "\n",
    "num_features = X03.shape[1]  # Number of non-image features\n",
    "\n",
    "# Define the CNN model for feature extraction\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 grayscale images\n",
    "\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Define the model to output the flattened features\n",
    "feature_extraction_model = Model(inputs=image_input, outputs=flatten)\n",
    "# feature_extraction_model.summary()\n",
    "\n",
    "# Extract features from the training and validation image data\n",
    "image_features_train = feature_extraction_model.predict(pictures_train)\n",
    "image_features_val = feature_extraction_model.predict(pictures_val)\n",
    "\n",
    "# Combine image features with non-image data\n",
    "combined_train_data = np.concatenate([image_features_train, X03_train], axis=1)\n",
    "combined_val_data = np.concatenate([image_features_val, X03_val], axis=1)\n",
    "\n",
    "# The objective function for Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        # 'n_estimators': 150,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 0.25),\n",
    "        # 'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 100.0),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 5, 100.0),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 50.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 96, 1024),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 0.8),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.70, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 2, 5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 250),\n",
    "    }\n",
    "\n",
    "    # run the model, fit and predict \n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(\n",
    "        combined_train_data, y03_train,\n",
    "        eval_set=[(combined_val_data, y03_val)],\n",
    "        eval_metric='mae',\n",
    "        callbacks=[LightGBMPruningCallback(trial, 'l1'),early_stopping(stopping_rounds=5)]\n",
    "    )\n",
    "    \n",
    "    y_preds = model.predict(combined_val_data)\n",
    "    \n",
    "    mae = mean_absolute_error(y03_val, y_preds)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Create a study and start the optimization process\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=350)\n",
    "\n",
    "# Print the best parameters\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print('  Value: {}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b196cc-9b77-4eb3-9591-a4ea01e67ae4",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "  Value: 20.656476474109315\n",
    "  Params: \n",
    "    lambda_l1: 43.717089120026756\n",
    "    lambda_l2: 6.587549445785165\n",
    "    num_leaves: 1922\n",
    "    feature_fraction: 0.668370377660226\n",
    "    bagging_fraction: 0.8886019976321862\n",
    "    bagging_freq: 1\n",
    "    min_child_samples: 16\n",
    "Best trial:\n",
    "  Value: 20.145705597469057\n",
    "  Params: \n",
    "    lambda_l1: 0.10945207477477581\n",
    "    lambda_l2: 9.03876231037474\n",
    "    num_leaves: 1961\n",
    "    feature_fraction: 0.780528052763212\n",
    "    bagging_fraction: 0.9480446922239267\n",
    "    bagging_freq: 7\n",
    "    min_child_samples: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1st try\n",
    "Best trial:\n",
    "  Value: 21.53931570838462\n",
    "  Params: \n",
    "    lambda_l1: 2.01546274100036\n",
    "    lambda_l2: 0.7111412857087858\n",
    "    num_leaves: 242\n",
    "    feature_fraction: 0.6227918411296163\n",
    "    bagging_fraction: 0.9655103122297912\n",
    "    bagging_freq: 7\n",
    "    min_child_samples: 27\n",
    "\n",
    "2nd try Increased the parameter space notably \n",
    "num leaves (2,256) -> (128,1024)\n",
    "min_clild_samples (5,100) -> (10,250)\n",
    "Best trial:\n",
    "  Value: 19.440244621935555\n",
    "  Params: \n",
    "    lambda_l1: 9.942178625506006\n",
    "    lambda_l2: 6.021388788503392\n",
    "    num_leaves: 927\n",
    "    feature_fraction: 0.7971447195854893\n",
    "    bagging_fraction: 0.9630138347471484\n",
    "    bagging_freq: 5\n",
    "    min_child_samples: 25\n",
    "    \n",
    "3nd try Increased the parameter space notably \n",
    "num leaves             (2,256) -> (128,2048)\n",
    "'lambda_l1':           (1e-8, 10.0) -> (1e-8, 50.0)\n",
    "'lambda_l2':           (1e-8, 10.0) -> (1e-8, 50.0)\n",
    "feature_fraction':     (0.4, 1.0) -> (0.5, 0.9)\n",
    "Best trial:\n",
    "  Value: 18.961424118310052\n",
    "  Params: \n",
    "    lambda_l1: 48.11818528734888\n",
    "    lambda_l2: 6.7716539555661415\n",
    "    num_leaves: 1892\n",
    "    feature_fraction: 0.6871792889443591\n",
    "    bagging_fraction: 0.9856255101027098\n",
    "    bagging_freq: 1\n",
    "    min_child_samples: 14\n",
    "\n",
    "4th try Increased the parameter space notably \n",
    "'rmse' -> mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "24f655f1-88a0-4699-97cc-5b99696b5e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 18.961424118310052\n",
      "Root Mean Squared Error: 35.85037670426074\n",
      "R^2 Score: 0.9539464302988118\n"
     ]
    }
   ],
   "source": [
    "best_param = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 4500,\n",
    "    'learning_rate': trial.suggest_float('learning_rate', 1e-8, 0.25),\n",
    "    'lambda_l1': trial.suggest_float('lambda_l1', 5, 100.0),\n",
    "    'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 50.0),\n",
    "    'num_leaves': trial.suggest_int('num_leaves', 96, 1024),\n",
    "    'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 0.8),\n",
    "    'bagging_fraction': trial.suggest_float('bagging_fraction', 0.70, 1.0),\n",
    "    'bagging_freq': trial.suggest_int('bagging_freq', 2, 5),\n",
    "    'min_child_samples': trial.suggest_int('min_child_samples', 5, 250),\n",
    "}\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Assuming combined_train_data, y03_train, combined_val_data, y03_val are already defined\n",
    "\n",
    "# Create the LightGBM regressor with the best hyperparameters\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(\n",
    "    combined_train_data, y03_train,\n",
    "    eval_set=[(combined_val_data, y03_val)],\n",
    "    eval_metric='rmse',\n",
    ")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_preds = model.predict(combined_val_data)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y03_val, y_preds)\n",
    "rmse = mean_squared_error(y03_val, y_preds, squared=False)\n",
    "r2 = r2_score(y03_val, y_preds)\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R^2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a3c33edd-39ec-4e32-992c-f3a478fa4463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73111, 64, 64)\n",
      "(73111, 59)\n",
      "CPU times: total: 11.9 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metadata_file2 = \"n0_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "glathida_rgis2 = pd.read_csv(metadata_file2, low_memory=False)\n",
    "# glathida_rgis2 = glathida_rgis2.dropna()\n",
    "print(np.shape(pictures))\n",
    "print(np.shape(glathida_rgis2))\n",
    "test = []\n",
    "for i in range(len(pictures)):\n",
    "    test.append(pictures[i].flatten())\n",
    "# glathida_rgis2['PICTURE'] = test\n",
    "# glathida_rgis2.to_csv('n0_wpics_metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a33ce0-8a80-47bf-993b-c38c46a41731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a study and start the optimization process:\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0553ef-e6fa-436d-99f4-989f44b4159f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266cc27-ee19-4dfe-af9f-8bfceee5bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2ddbef84-006a-4dd6-9c7d-127d0ccde5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_overfitting(estimator, score_func, X_train, y_train, X_test, y_test prob=False):\n",
    "    # input: score_func = function, like mean_absolute_error for regression\n",
    "    # input: prob = bool, to use either probability prediction or number/discrete prediction for score function\n",
    "    # checked 19/05/2024\n",
    "\n",
    "    if prob:\n",
    "        y_pred_train = estimator.predict_proba(X_train)\n",
    "        y_pred_test = estimator.predict_proba(X_test)\n",
    "    else:        \n",
    "        y_pred_train = estimator.predict(X_train)\n",
    "        y_pred_test = estimator.predict(X_test)\n",
    "    \n",
    "    accuracy_train = score_func(y_train, y_pred_train)\n",
    "    accuracy_test = score_func(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"Training Accuracy: {accuracy_train:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy_test:.4f}\")\n",
    "    \n",
    "def evaluation_plot(estimator, y_test, y_pred):\n",
    "    # input: estimator = xgb_cl - XGBClassifier with all the hyperparameter, for example\n",
    "    # input: y_test = we divided our y (labeled feature we want to know) into train, test, validation, y_test is the part from test \n",
    "    # input: y_pred = is the y values predicted for the X_test\n",
    "    # plot the figures from the feedback document of the inital project in applied machine learning 2024 \n",
    "    # (Diversion, Distribution Residuals and Relative Errors)\n",
    "    # checked 04/06/2024\n",
    "\n",
    "    y_test = np.array(y_test) \n",
    "    residuals = y_test - y_pred\n",
    "    relative_errors = residuals / np.abs(y_test)\n",
    "    relative_errors = relative_errors[np.abs(relative_errors) <= 1.5]\n",
    "    percentile_90 = np.percentile(np.abs(residuals), 90)\n",
    "    high_residual_mask = np.abs(residuals) <= percentile_90\n",
    "\n",
    "    # Plot the Distribution of the Residuals and the Relative Errors\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    ax1.hist(residuals, bins='auto')\n",
    "    ax1.set_title('Distribution of Residuals')\n",
    "    ax1.set_xlabel('Residuals')\n",
    "    ax1.set_ylabel('Count')\n",
    "    #ax1.set_xlim()\n",
    "    \n",
    "    ax2.hist(relative_errors, bins='auto')\n",
    "    ax2.set_title('Distribution of Relative Errors')\n",
    "    ax2.set_xlabel('Relative Prediction Error')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_xlim(-1.5, 1.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot the Diversion\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, c='blue', alpha=0.1, label='100th percentile')\n",
    "    plt.scatter(y_test[high_residual_mask], y_pred[high_residual_mask], c='green', alpha=0.1, label='residual <= 90th percentile')\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='orange', linewidth=2)\n",
    "    # plt.ylim((0,1250))\n",
    "    # plt.xlim((0,1250))\n",
    "    \n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Prediction')\n",
    "    plt.title('Diversion')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the RMSE for training and validation sets\n",
    "    results = estimator.evals_result()\n",
    "    epochs = len(results['validation_0']['mae'])\n",
    "    x_axis = range(0, epochs)\n",
    "\n",
    "    # Plot RMSE and MAE metric\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    ax1.plot(x_axis, results['validation_0']['rmse'], label='Train')\n",
    "    ax1.plot(x_axis, results['validation_1']['rmse'], label='Test')\n",
    "    ax1.plot(x_axis, results['validation_2']['rmse'], label='Validation')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('RMSE')\n",
    "    ax1.set_title('Evolution of the Root Mean Squared Error')\n",
    "\n",
    "    ax2.plot(x_axis, results['validation_0']['mae'], label='Train')\n",
    "    ax2.plot(x_axis, results['validation_1']['mae'], label='Test')\n",
    "    ax2.plot(x_axis, results['validation_2']['mae'], label='Validation')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_title('Evolution of the Mean Absolute Error')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d6f70390-49b1-4ea3-97bb-7815afa1bceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LGBMRegressor' object has no attribute 'evals_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluation_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43my03_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_preds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[134], line 47\u001b[0m, in \u001b[0;36mevaluation_plot\u001b[1;34m(estimator, y_test, y_pred)\u001b[0m\n\u001b[0;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Plot the RMSE for training and validation sets\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevals_result\u001b[49m()\n\u001b[0;32m     48\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     49\u001b[0m x_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, epochs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LGBMRegressor' object has no attribute 'evals_result'"
     ]
    }
   ],
   "source": [
    "evaluation_plot(model,y03_val, y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa7922-3ae9-494f-9244-86dde1941dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
