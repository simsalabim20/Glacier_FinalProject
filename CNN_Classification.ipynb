{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96890011-0d5e-4b6b-860e-3898c2e0ce7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import oggm\n",
    "from oggm import utils\n",
    "\n",
    "from __future__ import print_function, division   # Ensures Python3 printing & division standard\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,mean_squared_error, mean_absolute_error, r2_score, roc_curve,auc\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,export_graphviz\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from scipy.stats import randint, poisson\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "\n",
    "import csv\n",
    "\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef305a2-c83d-4e6b-9664-50d4701d6bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "metadata_file = \"metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "glathida_rgis = pd.read_csv(metadata_file, low_memory=False)\n",
    "\n",
    "# Group by 'RGIId' and get the unique 'Form' value for each 'RGIId'\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "# Function to convert 'Form' value to 2D vector\n",
    "def convert_to_2d_vector(form_value):\n",
    "    return [1, 0] if form_value == 1 else [0, 1]\n",
    "\n",
    "def convert_to_4d_vector(term_value):\n",
    "    if term_value == 0:\n",
    "        return [1, 0, 0, 0]\n",
    "    elif term_value == 1:\n",
    "        return [0, 1, 0, 0]\n",
    "    elif term_value == 2:\n",
    "        return [0, 0, 1, 0]\n",
    "    elif term_value == 5:\n",
    "        return [0, 0, 0, 1]\n",
    "    \n",
    "# Apply the conversion function\n",
    "unique_forms['Form_Vector'] = unique_forms['Form'].apply(convert_to_2d_vector)\n",
    "form_vectors_array = np.array(unique_forms['Form_Vector'].tolist())\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_term['Term_Vector'] = unique_term['TermType'].apply(convert_to_4d_vector)\n",
    "term_vectors_array = np.array(unique_term['Term_Vector'].tolist())\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "# print(unique_forms[['RGIId', 'Form_Vector']])\n",
    "# unique_forms['Form_Vector']\n",
    "# unique_term['Term_Vector']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600cff93-3431-4914-852b-1c031534f5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize_image(image_path, threshold=128):\n",
    "    \"\"\"\n",
    "    Reads an image and vectorizes it to 0 and 1 depending on the color.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: str, path to the image file\n",
    "\n",
    "    Returns:\n",
    "    - binary_vector: numpy array of 0s and 1s\n",
    "    \"\"\"\n",
    "    # Open the image and convert to RGB\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Define a blue color range\n",
    "    lower_blue = np.array([0, 0, 128])\n",
    "    upper_blue = np.array([127, 127, 255])\n",
    "    \n",
    "    # Create a mask for blue pixels\n",
    "    blue_mask = np.all((image_array >= lower_blue) & (image_array <= upper_blue), axis=-1)\n",
    "    \n",
    "    # Create a binary vector where blue is 1 and everything else is 0\n",
    "    binary_vector = blue_mask.astype(int)\n",
    "    \n",
    "    return binary_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "069bfe88-4955-46a5-96b4-72616b2c5e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Processes all images in the specified folder, vectorizing each one.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: str, path to the folder containing images\n",
    "\n",
    "    Returns:\n",
    "    - result_dict: dictionary, keys are image filenames and values are their binary vectors\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            binary_image = vectorize_image(image_path)\n",
    "            result_dict[filename] = binary_image\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc70f44-cd1d-415a-b466-a328f8703e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = r'C:\\Users\\damsg\\OGGM\\glacier_geometries_images_small_rotmir'  \n",
    "processed_images = process_folder(folder_path)\n",
    "\n",
    "def resize_array(array, size=(64, 64)):\n",
    "    # Convert the array to PIL Image\n",
    "    image = Image.fromarray(np.array(array, dtype='uint8'))\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size, resample=Image.BILINEAR)\n",
    "    # Convert the resized image back to numpy array\n",
    "    return np.array(resized_image)\n",
    "\n",
    "# Assuming 'data_dict' is your dictionary containing multiple arrays\n",
    "resized_arrays = [resize_array(array) for array in processed_images.values()]\n",
    "\n",
    "# Stack all resized arrays into a single numpy array\n",
    "resized_data_array = np.stack(resized_arrays, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9088a0-f748-44e7-a1fc-6783a1a73358",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9329fa41-c660-4238-b264-f2c93c7ec761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_64 (Conv2D)          (None, 64, 64, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_64 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_65 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_66 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 650,308\n",
      "Trainable params: 650,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 64, 64\n",
    "num_classes = 4 #Change to 2 for form to 4 for Termtype\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=128,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=256,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Dropout(rate=0.60))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a5016afb-f3c6-453c-8457-ce0320d24a51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18568\n",
      "2321\n",
      "18568\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(resized_data_array))\n",
    "print(len(form_vectors_array))\n",
    "y = [form_vectors_array[i] for i in range(len(form_vectors_array)) for _ in range(8)]\n",
    "y1 = [term_vectors_array[i] for i in range(len(term_vectors_array)) for _ in range(8)]\n",
    "\n",
    "print(len(y))\n",
    "print(y[0])\n",
    "X = resized_data_array\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size = 0.8, random_state=1)\n",
    "X_train0, X_test0, y_train1, y_test1 = train_test_split(X, y1,train_size = 0.8, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "32fea56e-5747-4a54-8771-8eb719d0960b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- TRAINING ---------\n",
      "465/465 [==============================] - 67s 142ms/step - loss: 1.1678 - categorical_accuracy: 0.6505 - val_loss: 0.8387 - val_categorical_accuracy: 0.8220\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['categorical_accuracy'])\n",
    "print('--------- TRAINING ---------')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(x = np.array(X_train0), y = np.array(y_train1),validation_data=(np.array(X_test0), np.array(y_test1)), \n",
    "                    epochs = 1, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56237d1-d317-44a8-9d28-61cc64b4a8e4",
   "metadata": {},
   "source": [
    "## Normal NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9f3d7ec1-f743-425a-907e-c4a6932c1a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81290, 53)\n",
      "--------- TRAINING ---------\n",
      "Epoch 1/5\n",
      "2033/2033 [==============================] - 6s 3ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "2033/2033 [==============================] - 5s 3ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "2033/2033 [==============================] - 6s 3ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "2033/2033 [==============================] - 7s 3ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "2033/2033 [==============================] - 7s 4ms/step - loss: 5.2049e-08 - categorical_accuracy: 1.0000 - val_loss: 5.0307e-08 - val_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# X0 = glathida_rgis.drop(['ith_m','ith_f','THICKNESS','RGIId'],axis=1) \n",
    "X0 = glathida_rgis.drop(['Form','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "X0 = glathida_rgis.drop(['TermType','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X0 = pd.DataFrame(scaler.fit_transform(X0.values), columns=X0.columns, index=X0.index)\n",
    "# y0 = glathida_rgis['Form'] \n",
    "y0 = glathida_rgis['TermType'] \n",
    "\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X0, y0,train_size = 0.8, random_state=1)\n",
    "print(np.shape(X0))\n",
    "model0 = Sequential([\n",
    "    Dense(54,activation='LeakyReLU'   ,name='input_layer'),\n",
    "    Dense(90,activation='relu'   ,name='hidden_layer1'),\n",
    "    Dense(90,activation='relu'   ,name='hidden_layer2'),\n",
    "    Dense(1, name='output')])\n",
    "\n",
    "model0.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "print('--------- TRAINING ---------')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model0.fit(x = np.array(X_train0), y = np.array(y_train0),validation_data=(np.array(X_test0), np.array(y_test0)), \n",
    "                    epochs = 5, callbacks=[early_stopping]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "01d9edbe-ef49-44c0-8bc1-51ed32132f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perm_importance = permutation_importance(model0, X_test0, y_test0, scoring ='neg_mean_absolute_error', n_repeats=5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a238a331-1705-433c-b164-f9b6468e603e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Zmed: 0.005709929073745945\n",
      "2. Aspect: 0.004124656653926662\n",
      "3. Form: 0.0032511009947928217\n",
      "4. POINT_LAT: 0.0028006188892364613\n",
      "5. RGI: 0.0015365256226289703\n",
      "6. aspect_gfa: 0.0013626384053841202\n",
      "7. aspect_300: 0.0010358497998848803\n",
      "8. Zmax: 0.00052399357424735\n",
      "9. smb: 0.0003666735084903561\n",
      "10. aspect_50: 0.00034876667908219084\n",
      "11. slope_lon_gf100: 0.00027349420798070676\n",
      "12. curv_300: 0.0002556475910718836\n",
      "13. slope_lon_gf300: 0.00022655289792580246\n",
      "14. dist_from_border_km_geom: 0.00018556618321193818\n",
      "15. slope_lon_gf450: 0.00015092586798735042\n",
      "16. slope_lat: 0.00010904609561013245\n",
      "17. vy_gf150: 0.00010066974887859014\n",
      "18. vx_gf150: 5.431998820853989e-05\n",
      "19. vx_gf300: 2.8750925930309813e-05\n",
      "20. curv_50: 2.5984332648920637e-05\n",
      "21. vy: 1.5212649709073211e-05\n",
      "22. vy_gf300: 1.2787207047448845e-05\n",
      "23. vy_gf100: 1.0764569195886864e-05\n",
      "24. vx_gfa: 3.74171580541649e-06\n",
      "25. vy_gf50: -1.527155426273019e-06\n",
      "26. dvx_dy: -3.333697056728813e-06\n",
      "27. dvy_dy: -8.650500142592943e-06\n",
      "28. dvy_dx: -1.2245427151635901e-05\n",
      "29. dvx_dx: -1.94867799252596e-05\n",
      "30. vx_gf50: -2.879515504654595e-05\n",
      "31. slope_lon: -2.953081705719951e-05\n",
      "32. vx_gf450: -3.111862729784365e-05\n",
      "33. vx: -4.066022293505167e-05\n",
      "34. vx_gf100: -4.5916789129529786e-05\n",
      "35. vy_gfa: -4.977516776323298e-05\n",
      "36. vy_gf450: -5.263788961068494e-05\n",
      "37. slope_lon_gf50: -7.352727193635778e-05\n",
      "38. curv_gfa: -9.014246897559586e-05\n",
      "39. slope_lat_gf150: -9.13107645754585e-05\n",
      "40. slope_lon_gfa: -0.00012600511830950233\n",
      "41. slope_lon_gf150: -0.00030718408019836385\n",
      "42. slope_lat_gf450: -0.00034425374863172875\n",
      "43. dmdtda_hugo: -0.00037978265949717427\n",
      "44. slope_lat_gf100: -0.00039420699730773333\n",
      "45. slope_lat_gfa: -0.00041090299455541767\n",
      "46. slope_lat_gf50: -0.0005488607635729115\n",
      "47. POINT_LON: -0.0006902447777461296\n",
      "48. slope_lat_gf300: -0.0007446552347615487\n",
      "49. Lmax: -0.0007498592138790227\n",
      "50. Area: -0.0010190315329951737\n",
      "51. Slope: -0.0015997448437967243\n",
      "52. elevation: -0.003058483017767144\n",
      "53. Zmin: -0.004330756908253608\n"
     ]
    }
   ],
   "source": [
    "# perm_importance = permutation_importance(model0, X_test0, y_test0, scoring ='neg_mean_absolute_error', n_repeats=5, random_state=42)\n",
    "\n",
    "feature_importance_scores = perm_importance.importances_mean\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X0.columns  # Assuming X is a pandas DataFrame with feature names\n",
    "\n",
    "# Print or visualize feature importance\n",
    "sorted_feature_indices = feature_importance_scores.argsort()[::-1]\n",
    "sorted_feature_names = feature_names[sorted_feature_indices]\n",
    "\n",
    "for i, feature_name in enumerate(sorted_feature_names):\n",
    "    print(f\"{i+1}. {feature_name}: {feature_importance_scores[sorted_feature_indices[i]]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4b6f9-0901-46c0-b68f-487c7904789e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine CNN with NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa71172-485d-4581-9396-972cd97f5251",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Form CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d52eae9f-3974-417e-a4b3-d3764cb8bf49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)          [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 62, 62, 32)   320         ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_72 (MaxPooling2D  (None, 31, 31, 32)  0           ['conv2d_72[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 29, 29, 64)   18496       ['max_pooling2d_72[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_73 (MaxPooling2D  (None, 14, 14, 64)  0           ['conv2d_73[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 12, 12, 128)  73856       ['max_pooling2d_73[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_74 (MaxPooling2D  (None, 6, 6, 128)   0           ['conv2d_74[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 4, 4, 256)    295168      ['max_pooling2d_74[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_75 (MaxPooling2D  (None, 2, 2, 256)   0           ['conv2d_75[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_18 (Flatten)           (None, 1024)         0           ['max_pooling2d_75[0][0]']       \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 64)           65600       ['flatten_18[0][0]']             \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 53)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 117)          0           ['dense_77[0][0]',               \n",
      "                                                                  'input_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 117)          13806       ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 180)          21240       ['dense_78[0][0]']               \n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 32)           5792        ['dense_79[0][0]']               \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 1)            33          ['dense_81[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 494,311\n",
      "Trainable params: 494,311\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "num_features = 53 #Features in dataset\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 RGB images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(117, activation='relu')(combined_input)\n",
    "fc2 = Dense(180, activation='relu')(fc1)\n",
    "fc3 = Dense(180, activation='relu')(fc2)\n",
    "fc3 = Dense(32, activation='relu')(fc2)\n",
    "output = Dense(1, activation='sigmoid')(fc3)  # Output layer for binary classification\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "combined_model.summary()\n",
    "\n",
    "\n",
    "# history = combined_model.fit(inputs = [resized_data_array,]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd00a871-ca2c-4017-baf5-ab4dab898fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = r'C:\\Users\\damsg\\OGGM\\glacier_geometries_images_small'  \n",
    "processed_images = process_folder(folder_path)\n",
    "\n",
    "def resize_array(array, size=(64, 64)):\n",
    "    # Convert the array to PIL Image\n",
    "    image = Image.fromarray(np.array(array, dtype='uint8'))\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size, resample=Image.BILINEAR)\n",
    "    # Convert the resized image back to numpy array\n",
    "    return np.array(resized_image)\n",
    "\n",
    "# Assuming 'data_dict' is your dictionary containing multiple arrays\n",
    "resized_arrays = [resize_array(array) for array in processed_images.values()]\n",
    "\n",
    "# Stack all resized arrays into a single numpy array\n",
    "resized_data_array = np.stack(resized_arrays, axis=0)\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_forms['Form_Vector'] = unique_forms['Form'].apply(convert_to_2d_vector)\n",
    "form_vectors_array = np.array(unique_forms['Form_Vector'].tolist())\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "unique_term['Term_Vector'] = unique_term['TermType'].apply(convert_to_4d_vector)\n",
    "term_vectors_array = np.array(unique_term['Term_Vector'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da67738b-7975-42c1-907f-13977435dec9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81290, 64, 64)\n",
      "(81290,)\n"
     ]
    }
   ],
   "source": [
    "pictures = []\n",
    "current_rgi_id = None\n",
    "i = -1  # Initial value of i\n",
    "\n",
    "for rgi_id in glathida_rgis['RGIId']:\n",
    "    if rgi_id != current_rgi_id:\n",
    "        i += 1  # Increment i when RGIId changes\n",
    "        current_rgi_id = rgi_id\n",
    "    pictures.append(resized_data_array[i])\n",
    "\n",
    "# Convert pictures to a numpy array if needed\n",
    "pictures = np.array(pictures)\n",
    "print(np.shape(pictures))\n",
    "print(np.shape(glathida_rgis['RGIId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9454b251-2f2f-452d-8e58-e1d28dd491c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pictures = resized_data_array\n",
    "\n",
    "y01 = glathida_rgis['Form'] \n",
    "y02_values = glathida_rgis['TermType']\n",
    "\n",
    "y02 = np.array([convert_to_4d_vector(term_value) for term_value in y02_values])\n",
    "# y02_one_hot = [convert_to_4d_vector(term_value) for term_value in y02_values]\n",
    "\n",
    "# Convert the list to a numpy array if needed\n",
    "# y02 = np.array(y02_one_hot)\n",
    "\n",
    "\n",
    "y03 = glathida_rgis['THICKNESS']\n",
    "\n",
    "X01 = glathida_rgis.drop(['Form','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "X02 = glathida_rgis.drop(['TermType','RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "X03 = glathida_rgis.drop(['RGIId','ith_m','ith_f','THICKNESS'],axis=1) \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X01 = pd.DataFrame(scaler.fit_transform(X01.values), columns=X01.columns, index=X01.index)\n",
    "X02 = pd.DataFrame(scaler.fit_transform(X02.values), columns=X02.columns, index=X02.index)\n",
    "X03 = pd.DataFrame(scaler.fit_transform(X03.values), columns=X03.columns, index=X03.index)\n",
    "\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "unique_term  = glathida_rgis.groupby('RGIId')['TermType'].first().reset_index()\n",
    "\n",
    "X01_train, X01_test, y01_train, y01_test = train_test_split(X01, y01,train_size = 0.8, random_state=1)\n",
    "X02_train, X02_test, y02_train, y02_test = train_test_split(X02, y02,train_size = 0.8, random_state=1)\n",
    "X03_train, X03_test, y03_train, y03_test = train_test_split(X03, y03,train_size = 0.8, random_state=1)\n",
    "#Shooting for form\n",
    "pictures_train, pictures_val, X01_train, X01_val, y01_train, y01_val = train_test_split(\n",
    "    pictures, X01, y01, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=2,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Form_model_weights.h5',  # Full file path to save the model weights\n",
    "    monitor='val_loss',               # Metric to monitor\n",
    "    save_best_only=True,              # Save only the best weights\n",
    "    save_weights_only=True            # Save only the weights (not the entire model)\n",
    ")\n",
    "\n",
    "combined_model.fit(\n",
    "    [pictures_train, X01_train],  # Inputs: list of image data and non-image data\n",
    "    y01_train,                    # Target labels\n",
    "    epochs=7,                    # Number of epochs\n",
    "    batch_size=32,                # Batch size\n",
    "    validation_data=([pictures_val, X01_val], y01_val),  # Validation data\n",
    "    callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    ")\n",
    "combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Form_model_weights_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc163ead-10e3-4c47-bbbc-de888c537be6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Termtype CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "591ac37d-6e88-49da-b6c4-1dade1613f60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 62, 62, 32)   320         ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_80 (MaxPooling2D  (None, 31, 31, 32)  0           ['conv2d_80[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 29, 29, 64)   18496       ['max_pooling2d_80[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_81 (MaxPooling2D  (None, 14, 14, 64)  0           ['conv2d_81[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 12, 12, 128)  73856       ['max_pooling2d_81[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_82 (MaxPooling2D  (None, 6, 6, 128)   0           ['conv2d_82[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 4, 4, 256)    295168      ['max_pooling2d_82[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_83 (MaxPooling2D  (None, 2, 2, 256)   0           ['conv2d_83[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_20 (Flatten)           (None, 1024)         0           ['max_pooling2d_83[0][0]']       \n",
      "                                                                                                  \n",
      " dense_89 (Dense)               (None, 64)           65600       ['flatten_20[0][0]']             \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 53)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 117)          0           ['dense_89[0][0]',               \n",
      "                                                                  'input_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_90 (Dense)               (None, 117)          13806       ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " dense_91 (Dense)               (None, 180)          21240       ['dense_90[0][0]']               \n",
      "                                                                                                  \n",
      " dense_93 (Dense)               (None, 32)           5792        ['dense_91[0][0]']               \n",
      "                                                                                                  \n",
      " dense_94 (Dense)               (None, 4)            132         ['dense_93[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 494,410\n",
      "Trainable params: 494,410\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, concatenate\n",
    "num_features = 53 #Features in dataset\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 Greyscale images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(117, activation='relu')(combined_input)\n",
    "fc2 = Dense(180, activation='relu')(fc1)\n",
    "fc3 = Dense(180, activation='relu')(fc2)\n",
    "fc3 = Dense(32, activation='relu')(fc2)\n",
    "output = Dense(4, activation='sigmoid')(fc3)  # Output layer for multi classification\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "combined_model.summary()\n",
    "\n",
    "\n",
    "# history = combined_model.fit(inputs = [resized_data_array,]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c89c58d6-ab5c-426b-b974-a276eb41c83a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "2033/2033 [==============================] - 317s 155ms/step - loss: 0.1012 - accuracy: 0.9629 - val_loss: 0.0768 - val_accuracy: 0.9705\n",
      "Epoch 2/7\n",
      "2033/2033 [==============================] - 317s 156ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0455 - val_accuracy: 0.9814\n",
      "Epoch 3/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0011 - val_accuracy: 0.9997\n",
      "Epoch 4/7\n",
      "2033/2033 [==============================] - 324s 159ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 1.8127e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0138 - val_accuracy: 0.9945\n",
      "Epoch 6/7\n",
      "2033/2033 [==============================] - 317s 156ms/step - loss: 2.5115e-04 - accuracy: 0.9999 - val_loss: 2.7377e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/7\n",
      "2033/2033 [==============================] - 322s 158ms/step - loss: 1.5606e-06 - accuracy: 1.0000 - val_loss: 7.9302e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Shooting for TermType\n",
    "pictures_train, pictures_val, X02_train, X02_val, y02_train, y02_val = train_test_split(\n",
    "    pictures, X02, y02, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=3,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Term_model_weights.h5',  # Full file path to save the model weights\n",
    "    monitor='val_loss',               # Metric to monitor\n",
    "    save_best_only=True,              # Save only the best weights\n",
    "    save_weights_only=True            # Save only the weights (not the entire model)\n",
    ")\n",
    "# Train the model with early stopping\n",
    "combined_model.fit(\n",
    "    [pictures_train, X02_train],  # Inputs: list of image data and non-image data\n",
    "    y02_train,                    # Target labels\n",
    "    epochs=7,                    # Number of epochs\n",
    "    batch_size=32,                # Batch size\n",
    "    validation_data=([pictures_val, X02_val], y02_val),  # Validation data\n",
    "    callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    ")\n",
    "\n",
    "combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Term_model_weights_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f8a2a-a28b-47c4-acc6-977872f62bf5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Thickness CNN + NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "222a0150-44d7-4abd-ace0-64607c832f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_features = 54 #Features in dataset\n",
    "# Define input layers for both image and non-image data\n",
    "image_input = Input(shape=(64, 64, 1))  # Assuming 64x64 RGB images\n",
    "non_image_input = Input(shape=(num_features,))  # Specify the number of features for your non-image data\n",
    "\n",
    "# CNN for image data\n",
    "conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "flatten = layers.Flatten()(pool4)\n",
    "\n",
    "# Add the dense layer with 64 units and ReLU activation\n",
    "dense_64_relu = Dense(64, activation='relu')(flatten)\n",
    "\n",
    "# Concatenate the dense layer output with non-image data\n",
    "combined_input = concatenate([dense_64_relu, non_image_input])\n",
    "\n",
    "# Fully connected layers for combined data\n",
    "fc1 = Dense(117, activation='relu')(combined_input)\n",
    "fc2 = Dense(150, activation='relu')(fc1)\n",
    "fc3 = Dense(75, activation='relu')(fc2)\n",
    "fc3 = Dense(32, activation='relu')(fc2)\n",
    "output = Dense(1)(fc3)  # Output layer for regression\n",
    "\n",
    "# Define the combined model\n",
    "combined_model = Model(inputs=[image_input, non_image_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "combined_model.compile(optimizer='adam',loss= 'mean_absolute_error',metrics=['mean_absolute_error'])\n",
    "# Print the model summary\n",
    "# combined_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2f08837-7c87-4d21-8a53-fa81bf4c054c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2033/2033 [==============================] - 239s 117ms/step - loss: 78.2529 - mean_absolute_error: 78.2529 - val_loss: 57.1098 - val_mean_absolute_error: 57.1098\n",
      "Epoch 2/100\n",
      "2033/2033 [==============================] - 227s 112ms/step - loss: 52.1564 - mean_absolute_error: 52.1564 - val_loss: 48.8451 - val_mean_absolute_error: 48.8451\n",
      "Epoch 3/100\n",
      "2033/2033 [==============================] - 277s 136ms/step - loss: 48.3044 - mean_absolute_error: 48.3044 - val_loss: 47.0176 - val_mean_absolute_error: 47.0176\n",
      "Epoch 4/100\n",
      "2033/2033 [==============================] - 230s 113ms/step - loss: 46.4882 - mean_absolute_error: 46.4882 - val_loss: 46.1673 - val_mean_absolute_error: 46.1673\n",
      "Epoch 5/100\n",
      "2033/2033 [==============================] - 237s 117ms/step - loss: 45.4935 - mean_absolute_error: 45.4935 - val_loss: 48.8119 - val_mean_absolute_error: 48.8119\n",
      "Epoch 6/100\n",
      "2033/2033 [==============================] - 242s 119ms/step - loss: 44.7931 - mean_absolute_error: 44.7931 - val_loss: 45.6364 - val_mean_absolute_error: 45.6364\n",
      "Epoch 7/100\n",
      "2033/2033 [==============================] - 233s 115ms/step - loss: 44.0089 - mean_absolute_error: 44.0089 - val_loss: 44.2848 - val_mean_absolute_error: 44.2848\n",
      "Epoch 8/100\n",
      "2033/2033 [==============================] - 254s 125ms/step - loss: 43.1698 - mean_absolute_error: 43.1698 - val_loss: 42.9874 - val_mean_absolute_error: 42.9874\n",
      "Epoch 9/100\n",
      "2033/2033 [==============================] - 284s 140ms/step - loss: 42.8427 - mean_absolute_error: 42.8427 - val_loss: 42.2677 - val_mean_absolute_error: 42.2677\n",
      "Epoch 10/100\n",
      "2033/2033 [==============================] - 244s 120ms/step - loss: 42.0711 - mean_absolute_error: 42.0711 - val_loss: 43.0842 - val_mean_absolute_error: 43.0842\n",
      "Epoch 11/100\n",
      "2033/2033 [==============================] - 267s 131ms/step - loss: 41.5452 - mean_absolute_error: 41.5452 - val_loss: 41.1163 - val_mean_absolute_error: 41.1163\n",
      "Epoch 12/100\n",
      "2033/2033 [==============================] - 253s 124ms/step - loss: 40.8611 - mean_absolute_error: 40.8611 - val_loss: 41.1068 - val_mean_absolute_error: 41.1068\n",
      "Epoch 13/100\n",
      "2033/2033 [==============================] - 248s 122ms/step - loss: 40.3146 - mean_absolute_error: 40.3146 - val_loss: 40.8747 - val_mean_absolute_error: 40.8747\n",
      "Epoch 14/100\n",
      "2033/2033 [==============================] - 247s 122ms/step - loss: 39.8022 - mean_absolute_error: 39.8022 - val_loss: 40.5382 - val_mean_absolute_error: 40.5382\n",
      "Epoch 15/100\n",
      "2033/2033 [==============================] - 313s 154ms/step - loss: 39.4646 - mean_absolute_error: 39.4646 - val_loss: 40.2398 - val_mean_absolute_error: 40.2398\n",
      "Epoch 16/100\n",
      "2033/2033 [==============================] - 250s 123ms/step - loss: 38.7992 - mean_absolute_error: 38.7992 - val_loss: 40.2512 - val_mean_absolute_error: 40.2512\n",
      "Epoch 17/100\n",
      "2033/2033 [==============================] - 317s 156ms/step - loss: 38.5500 - mean_absolute_error: 38.5500 - val_loss: 39.4939 - val_mean_absolute_error: 39.4939\n",
      "Epoch 18/100\n",
      "2033/2033 [==============================] - 255s 125ms/step - loss: 38.1310 - mean_absolute_error: 38.1310 - val_loss: 39.6788 - val_mean_absolute_error: 39.6788\n",
      "Epoch 19/100\n",
      "2033/2033 [==============================] - 244s 120ms/step - loss: 37.8596 - mean_absolute_error: 37.8596 - val_loss: 39.9493 - val_mean_absolute_error: 39.9493\n",
      "Epoch 20/100\n",
      "2033/2033 [==============================] - 328s 161ms/step - loss: 37.5871 - mean_absolute_error: 37.5871 - val_loss: 38.3360 - val_mean_absolute_error: 38.3360\n",
      "Epoch 21/100\n",
      "2033/2033 [==============================] - 326s 160ms/step - loss: 37.3245 - mean_absolute_error: 37.3245 - val_loss: 38.3415 - val_mean_absolute_error: 38.3415\n",
      "Epoch 22/100\n",
      "2033/2033 [==============================] - 328s 161ms/step - loss: 37.1897 - mean_absolute_error: 37.1897 - val_loss: 38.0080 - val_mean_absolute_error: 38.0080\n",
      "Epoch 23/100\n",
      "2033/2033 [==============================] - 338s 166ms/step - loss: 36.8644 - mean_absolute_error: 36.8644 - val_loss: 38.7310 - val_mean_absolute_error: 38.7310\n",
      "Epoch 24/100\n",
      "2033/2033 [==============================] - 280s 138ms/step - loss: 36.6851 - mean_absolute_error: 36.6851 - val_loss: 37.4636 - val_mean_absolute_error: 37.4636\n",
      "Epoch 25/100\n",
      "2033/2033 [==============================] - 333s 164ms/step - loss: 36.3666 - mean_absolute_error: 36.3666 - val_loss: 36.9458 - val_mean_absolute_error: 36.9458\n",
      "Epoch 26/100\n",
      "2033/2033 [==============================] - 272s 134ms/step - loss: 36.2004 - mean_absolute_error: 36.2004 - val_loss: 37.3994 - val_mean_absolute_error: 37.3994\n",
      "Epoch 27/100\n",
      "2033/2033 [==============================] - 340s 167ms/step - loss: 35.9953 - mean_absolute_error: 35.9953 - val_loss: 36.9505 - val_mean_absolute_error: 36.9505\n",
      "Epoch 28/100\n",
      "2033/2033 [==============================] - 335s 165ms/step - loss: 35.8701 - mean_absolute_error: 35.8701 - val_loss: 37.3734 - val_mean_absolute_error: 37.3734\n",
      "Epoch 29/100\n",
      "2033/2033 [==============================] - 344s 169ms/step - loss: 35.6913 - mean_absolute_error: 35.6913 - val_loss: 36.5043 - val_mean_absolute_error: 36.5043\n",
      "Epoch 30/100\n",
      "2033/2033 [==============================] - 333s 164ms/step - loss: 35.5296 - mean_absolute_error: 35.5296 - val_loss: 36.9134 - val_mean_absolute_error: 36.9134\n",
      "Epoch 31/100\n",
      "2033/2033 [==============================] - 332s 163ms/step - loss: 35.3923 - mean_absolute_error: 35.3923 - val_loss: 36.4745 - val_mean_absolute_error: 36.4745\n",
      "Epoch 32/100\n",
      "2033/2033 [==============================] - 268s 132ms/step - loss: 35.2087 - mean_absolute_error: 35.2087 - val_loss: 36.7148 - val_mean_absolute_error: 36.7148\n",
      "Epoch 33/100\n",
      "2033/2033 [==============================] - 266s 131ms/step - loss: 35.0289 - mean_absolute_error: 35.0289 - val_loss: 37.0754 - val_mean_absolute_error: 37.0754\n",
      "Epoch 34/100\n",
      "2033/2033 [==============================] - 333s 164ms/step - loss: 34.9495 - mean_absolute_error: 34.9495 - val_loss: 35.9997 - val_mean_absolute_error: 35.9997\n",
      "Epoch 35/100\n",
      "2033/2033 [==============================] - 268s 132ms/step - loss: 34.7833 - mean_absolute_error: 34.7833 - val_loss: 36.2071 - val_mean_absolute_error: 36.2071\n",
      "Epoch 36/100\n",
      "2033/2033 [==============================] - 270s 133ms/step - loss: 34.6171 - mean_absolute_error: 34.6171 - val_loss: 35.8259 - val_mean_absolute_error: 35.8259\n",
      "Epoch 37/100\n",
      "2033/2033 [==============================] - 273s 134ms/step - loss: 34.4185 - mean_absolute_error: 34.4185 - val_loss: 35.6004 - val_mean_absolute_error: 35.6004\n",
      "Epoch 38/100\n",
      "2033/2033 [==============================] - 333s 164ms/step - loss: 34.4693 - mean_absolute_error: 34.4693 - val_loss: 37.2840 - val_mean_absolute_error: 37.2840\n",
      "Epoch 39/100\n",
      "2033/2033 [==============================] - 260s 128ms/step - loss: 34.0915 - mean_absolute_error: 34.0915 - val_loss: 35.4160 - val_mean_absolute_error: 35.4160\n",
      "Epoch 40/100\n",
      "2033/2033 [==============================] - 258s 127ms/step - loss: 34.0587 - mean_absolute_error: 34.0587 - val_loss: 35.4065 - val_mean_absolute_error: 35.4065\n",
      "Epoch 41/100\n",
      "2033/2033 [==============================] - 260s 128ms/step - loss: 33.9520 - mean_absolute_error: 33.9520 - val_loss: 35.8511 - val_mean_absolute_error: 35.8511\n",
      "Epoch 42/100\n",
      "2033/2033 [==============================] - 323s 159ms/step - loss: 33.8300 - mean_absolute_error: 33.8300 - val_loss: 34.8409 - val_mean_absolute_error: 34.8409\n",
      "Epoch 43/100\n",
      "2033/2033 [==============================] - 312s 153ms/step - loss: 33.6966 - mean_absolute_error: 33.6966 - val_loss: 35.0454 - val_mean_absolute_error: 35.0454\n",
      "Epoch 44/100\n",
      "2033/2033 [==============================] - 289s 142ms/step - loss: 33.4830 - mean_absolute_error: 33.4830 - val_loss: 34.9030 - val_mean_absolute_error: 34.9030\n",
      "Epoch 45/100\n",
      "2033/2033 [==============================] - 306s 151ms/step - loss: 33.3728 - mean_absolute_error: 33.3728 - val_loss: 34.6714 - val_mean_absolute_error: 34.6714\n",
      "Epoch 46/100\n",
      "2033/2033 [==============================] - 274s 135ms/step - loss: 33.2520 - mean_absolute_error: 33.2520 - val_loss: 36.6427 - val_mean_absolute_error: 36.6427\n",
      "Epoch 47/100\n",
      "2033/2033 [==============================] - 251s 124ms/step - loss: 33.1611 - mean_absolute_error: 33.1611 - val_loss: 34.9670 - val_mean_absolute_error: 34.9670\n",
      "Epoch 48/100\n",
      "2033/2033 [==============================] - 248s 122ms/step - loss: 33.0449 - mean_absolute_error: 33.0449 - val_loss: 35.1187 - val_mean_absolute_error: 35.1187\n",
      "Epoch 49/100\n",
      "2033/2033 [==============================] - 251s 123ms/step - loss: 32.9276 - mean_absolute_error: 32.9276 - val_loss: 34.6445 - val_mean_absolute_error: 34.6445\n",
      "Epoch 50/100\n",
      "2033/2033 [==============================] - 262s 129ms/step - loss: 32.9057 - mean_absolute_error: 32.9057 - val_loss: 35.2516 - val_mean_absolute_error: 35.2516\n",
      "Epoch 51/100\n",
      "2033/2033 [==============================] - 308s 151ms/step - loss: 32.8324 - mean_absolute_error: 32.8324 - val_loss: 34.7312 - val_mean_absolute_error: 34.7312\n",
      "Epoch 52/100\n",
      "2033/2033 [==============================] - 246s 121ms/step - loss: 32.5427 - mean_absolute_error: 32.5427 - val_loss: 33.5194 - val_mean_absolute_error: 33.5194\n",
      "Epoch 53/100\n",
      "2033/2033 [==============================] - 245s 121ms/step - loss: 32.6309 - mean_absolute_error: 32.6309 - val_loss: 33.8505 - val_mean_absolute_error: 33.8505\n",
      "Epoch 54/100\n",
      "2033/2033 [==============================] - 273s 134ms/step - loss: 32.3978 - mean_absolute_error: 32.3978 - val_loss: 34.9597 - val_mean_absolute_error: 34.9597\n",
      "Epoch 55/100\n",
      "2033/2033 [==============================] - 248s 122ms/step - loss: 32.3316 - mean_absolute_error: 32.3316 - val_loss: 34.2169 - val_mean_absolute_error: 34.2169\n",
      "Epoch 56/100\n",
      "2033/2033 [==============================] - 245s 121ms/step - loss: 32.4617 - mean_absolute_error: 32.4617 - val_loss: 34.6137 - val_mean_absolute_error: 34.6137\n",
      "Epoch 57/100\n",
      "2033/2033 [==============================] - 243s 120ms/step - loss: 32.0920 - mean_absolute_error: 32.0920 - val_loss: 34.8724 - val_mean_absolute_error: 34.8724\n"
     ]
    }
   ],
   "source": [
    "#Shooting for TermType\n",
    "pictures_train, pictures_val, X03_train, X03_val, y03_train, y03_val = train_test_split(\n",
    "    pictures, X03, y03, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Thick_model_weights.h5',  # Full file path to save the model weights\n",
    "    monitor='val_loss',               # Metric to monitor\n",
    "    save_best_only=True,              # Save only the best weights\n",
    "    save_weights_only=True            # Save only the weights (not the entire model)\n",
    ")\n",
    "\n",
    "# Train the model with early stopping\n",
    "combined_model.fit(\n",
    "    [pictures_train, X03_train],  # Inputs: list of image data and non-image data\n",
    "    y03_train,                    # Target labels\n",
    "    epochs=100,                   # Number of epochs\n",
    "    batch_size=32,                # Batch size\n",
    "    validation_data=([pictures_val, X03_val], y03_val),  # Validation data\n",
    "    callbacks=[early_stopping,checkpoint]    # Include the early stopping callback\n",
    ")\n",
    "\n",
    "combined_model.save_weights(r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/Thick_model_weights_final.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc8c80-7b08-4696-bf95-5640edc122f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_model.load_weights('r'C:/Users/damsg/Desktop/Python/AppliedMachineLearning/Final_Project_Glacier/model_weights_final.h5'')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
