{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96890011-0d5e-4b6b-860e-3898c2e0ce7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import oggm\n",
    "from oggm import utils\n",
    "\n",
    "from __future__ import print_function, division   # Ensures Python3 printing & division standard\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,mean_squared_error, mean_absolute_error, r2_score, roc_curve,auc\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree,export_graphviz\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from scipy.stats import randint, poisson\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from ipywidgets import interactive\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "\n",
    "import csv\n",
    "\n",
    "%matplotlib qt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3ef305a2-c83d-4e6b-9664-50d4701d6bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               RGIId Form_Vector\n",
      "0     RGI60-01.08989   [0, 1, 0]\n",
      "1     RGI60-01.10006   [0, 1, 0]\n",
      "2     RGI60-01.10196   [0, 1, 0]\n",
      "3     RGI60-01.10557   [0, 1, 0]\n",
      "4     RGI60-01.10575   [0, 1, 0]\n",
      "...              ...         ...\n",
      "2316  RGI60-19.01298   [0, 1, 0]\n",
      "2317  RGI60-19.01406   [0, 1, 0]\n",
      "2318  RGI60-19.01407   [0, 1, 0]\n",
      "2319  RGI60-19.01415   [0, 1, 0]\n",
      "2320  RGI60-19.01721   [0, 1, 0]\n",
      "\n",
      "[2321 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       [0, 1, 0]\n",
       "1       [0, 1, 0]\n",
       "2       [0, 1, 0]\n",
       "3       [0, 1, 0]\n",
       "4       [0, 1, 0]\n",
       "          ...    \n",
       "2316    [0, 1, 0]\n",
       "2317    [0, 1, 0]\n",
       "2318    [0, 1, 0]\n",
       "2319    [0, 1, 0]\n",
       "2320    [0, 1, 0]\n",
       "Name: Form_Vector, Length: 2321, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "metadata_file = \"metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv\"\n",
    "glathida_rgis = pd.read_csv(metadata_file, low_memory=False)\n",
    "\n",
    "# Group by 'RGIId' and get the unique 'Form' value for each 'RGIId'\n",
    "unique_forms = glathida_rgis.groupby('RGIId')['Form'].first().reset_index()\n",
    "\n",
    "# Function to convert 'Form' value to 2D vector\n",
    "def convert_to_2d_vector(form_value):\n",
    "    return [1, 0, 0] if form_value == 1 else [0, 1, 0]\n",
    "\n",
    "# Apply the conversion function\n",
    "unique_forms['Form_Vector'] = unique_forms['Form'].apply(convert_to_2d_vector)\n",
    "form_vectors_array = np.array(unique_forms['Form_Vector'].tolist())\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(unique_forms[['RGIId', 'Form_Vector']])\n",
    "unique_forms['Form_Vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "600cff93-3431-4914-852b-1c031534f5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize_image(image_path, threshold=128):\n",
    "    \"\"\"\n",
    "    Reads an image and vectorizes it to 0 and 1 depending on the color.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: str, path to the image file\n",
    "\n",
    "    Returns:\n",
    "    - binary_vector: numpy array of 0s and 1s\n",
    "    \"\"\"\n",
    "    # Open the image and convert to RGB\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Define a blue color range\n",
    "    lower_blue = np.array([0, 0, 128])\n",
    "    upper_blue = np.array([127, 127, 255])\n",
    "    \n",
    "    # Create a mask for blue pixels\n",
    "    blue_mask = np.all((image_array >= lower_blue) & (image_array <= upper_blue), axis=-1)\n",
    "    \n",
    "    # Create a binary vector where blue is 1 and everything else is 0\n",
    "    binary_vector = blue_mask.astype(int)\n",
    "    \n",
    "    return binary_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "069bfe88-4955-46a5-96b4-72616b2c5e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Processes all images in the specified folder, vectorizing each one.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: str, path to the folder containing images\n",
    "\n",
    "    Returns:\n",
    "    - result_dict: dictionary, keys are image filenames and values are their binary vectors\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            binary_image = vectorize_image(image_path)\n",
    "            result_dict[filename] = binary_image\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6fc70f44-cd1d-415a-b466-a328f8703e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "folder_path = r'C:\\Users\\damsg\\OGGM\\glacier_geometries_images'  # Replace with your folder path\n",
    "processed_images = process_folder(folder_path)\n",
    "\n",
    "def resize_array(array, size=(160, 160)):\n",
    "    # Convert the array to PIL Image\n",
    "    image = Image.fromarray(np.array(array, dtype='uint8'))\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(size, resample=Image.BILINEAR)\n",
    "    # Convert the resized image back to numpy array\n",
    "    return np.array(resized_image)\n",
    "\n",
    "# Assuming 'data_dict' is your dictionary containing multiple arrays\n",
    "resized_arrays = [resize_array(array) for array in processed_images.values()]\n",
    "\n",
    "# Stack all resized arrays into a single numpy array\n",
    "resized_data_array = np.stack(resized_arrays, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f162f-c4e9-4401-ba86-da2cdfac3849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7affa036-4fc2-4413-9c94-2317a1edab7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# processed_images.keys()\n",
    "# #processed_images['RGI60-01.08989.png']\n",
    "\n",
    "# # Idiotset = [processed_images['RGI60-01.08989.png'], processed_images['RGI60-01.10006.png'], processed_images['RGI60-01.10196.png'], processed_images['RGI60-01.10557.png'], processed_images['RGI60-01.10575.png'], processed_images['RGI60-01.10612.png'], processed_images['RGI60-01.10621.png'], processed_images['RGI60-01.10655.png'], processed_images['RGI60-01.10689.png'], processed_images['RGI60-01.10778.png']]\n",
    "# Idiotset = []\n",
    "# Idiotlabel = [0,0,0,0,2,1,2,1,1,0]\n",
    "# # print(len(Idiotlabel))\n",
    "# # processed_images.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9329fa41-c660-4238-b264-f2c93c7ec761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_60 (Conv2D)          (None, 160, 160, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 80, 80, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 80, 80, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 40, 40, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 40, 40, 64)        0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 102400)            0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               13107328  \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,126,531\n",
      "Trainable params: 13,126,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 160, 160\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=32,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Conv2D(filters=64,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
    "\n",
    "model.add(layers.Dropout(rate=0.40))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f06406bb-acfe-4a9f-9b00-96a0ad1964d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unique_forms['Form_Vector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "32fea56e-5747-4a54-8771-8eb719d0960b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "73/73 [==============================] - 21s 272ms/step - loss: 0.8548 - categorical_accuracy: 0.8014\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 21s 290ms/step - loss: 0.7350 - categorical_accuracy: 0.8014\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 21s 294ms/step - loss: 0.6571 - categorical_accuracy: 0.8014\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 21s 287ms/step - loss: 0.6097 - categorical_accuracy: 0.8014\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 21s 284ms/step - loss: 0.5831 - categorical_accuracy: 0.8014\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 21s 292ms/step - loss: 0.5663 - categorical_accuracy: 0.8014\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 21s 290ms/step - loss: 0.5538 - categorical_accuracy: 0.8014\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 22s 303ms/step - loss: 0.5459 - categorical_accuracy: 0.8014\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 26s 352ms/step - loss: 0.5389 - categorical_accuracy: 0.8014\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 24s 323ms/step - loss: 0.5341 - categorical_accuracy: 0.8014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f86102f160>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# np.array(unique_forms['Form_Vector'])\n",
    "# resized_data_array = np.asarray(resized_data_array).astype(np.float32)\n",
    "# resized_data_array = np.asarray(resized_data_array).astype(np.float32)\n",
    "# y_test  = np.asarray(unique_forms['Form_Vector']).astype(np.float32)\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adadelta(),\n",
    "              metrics=['categorical_accuracy'])\n",
    "model.fit(x = resized_data_array,y = form_vectors_array,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9f3d7ec1-f743-425a-907e-c4a6932c1a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 1]), list([0, 1]), list([0, 1]), ..., list([0, 1]),\n",
       "       list([0, 1]), list([0, 1])], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(unique_forms['Form_Vector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1f0b7ad5-75ee-4d5c-9adf-cdbdc4ba13ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2321, 3)\n"
     ]
    }
   ],
   "source": [
    "# y_test  = np.asarray(unique_forms['Form_Vector']).astype(np.float32)\n",
    "# form_vectors_array = np.array(unique_forms['Form_Vector'].tolist())\n",
    "print(np.shape(form_vectors_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde269b-1e9d-4b5a-b1b5-16530044ebf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
