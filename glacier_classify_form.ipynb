{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'metadata19_hmineq0.0_tmin20050000_mean_grid_20.csv'\n",
    "glathida_rgis = pd.read_csv(data_name, low_memory = False)\n",
    "glathida_rgis = glathida_rgis.dropna()\n",
    "df = glathida_rgis.drop(columns = 'RGIId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Glacier :  2888361\n",
      "1 Ice cap :  1011750\n",
      "2 Perennial snowfield :  0\n",
      "3 Seasonal snow-field :  0\n",
      "4 Not assigned :  0\n"
     ]
    }
   ],
   "source": [
    "glacierForms = ('Glacier', 'Ice cap', 'Perennial snowfield', 'Seasonal snow-field', 'Not assigned')\n",
    "glacierID = (0, 1, 2, 3, 9)\n",
    "\n",
    "for i in range(len(glacierForms)):\n",
    "    print(i, glacierForms[i],': ', np.size(df[df['Form'] == glacierID[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only two of the Forms exists. Why are the other included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, test_size, target):\n",
    "    # Initial data split into x and y values.\n",
    "    xData = pd.DataFrame(data)\n",
    "    xData = xData.drop(columns = [target])\n",
    "    # Target\n",
    "    yData = data[target]\n",
    "\n",
    "    # Split into test and training data\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(xData, yData, test_size = test_size, random_state = 42)\n",
    "\n",
    "    return xTrain, xTest, yTrain, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = split(df, 0.1, 'Form')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron (MLP)\n",
    "def ClassMLP_crude(xTrain, xTest, yTrain, yTest):\n",
    "    # Define and train MLP classifier\n",
    "    ClassifierMLP = MLPClassifier(random_state = 42, early_stopping=True)\n",
    "    \n",
    "    # Train the model on training data\n",
    "    ClassifierMLP.fit(xTrain, yTrain)\n",
    "\n",
    "    # Compute predictions from trained model:\n",
    "    pre = ClassifierMLP.predict(xTest)\n",
    "    acc = accuracy_score(yTest, pre)\n",
    "    \n",
    "    return acc, pre    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "0.8513809732573433\n",
      "\n",
      "Clasification prediction:\n",
      "0 Glacier 5498\n",
      "1 Ice cap 1345\n",
      "2 Perennial snowfield 0\n",
      "3 Seasonal snow-field 0\n",
      "4 Not assigned 0\n"
     ]
    }
   ],
   "source": [
    "acc, pre = ClassMLP_crude(xTrain, xTest, yTrain, yTest)\n",
    "\n",
    "print('Accuracy:')\n",
    "print(acc)\n",
    "print()\n",
    "print('Clasification prediction:')\n",
    "for i in range(len(glacierForms)):\n",
    "    print(i, glacierForms[i], len(pre[np.where(pre == i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter optimization with grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated hidden layer neurons: 176, 132 and 106\n"
     ]
    }
   ],
   "source": [
    "# Number of output neurons, Number of input neurons, Number of samples in training set, scaling factor in range 2-10.\n",
    "def hiddenLayerSize(No, Ni, Ns, alpha): # Tries to estimate optimal hidden layer neurons.\n",
    "    Nh = Ns / (alpha * (Ni + No))\n",
    "    return Nh\n",
    "No = 2\n",
    "\n",
    "Nh1 = int(hiddenLayerSize(No, np.shape(xTrain)[1], np.shape(xTrain)[0], 6))\n",
    "Nh2 = int(hiddenLayerSize(No, np.shape(xTrain)[1], np.shape(xTrain)[0], 8))\n",
    "Nh3 = int(hiddenLayerSize(No, np.shape(xTrain)[1], np.shape(xTrain)[0], 10))\n",
    "print(f'Estimated hidden layer neurons: {Nh1}, {Nh2} and {Nh3}')\n",
    "\n",
    "hParamGrid = {'activation': ['relu', 'tanh'],\n",
    "               'alpha': [0.0001, 0.001, 0.01],\n",
    "               'solver': ['adam', 'sgd'],\n",
    "               'early_stopping': [True],\n",
    "               'learning_rate': ['constant', 'adaptive'],\n",
    "               'hidden_layer_sizes': [(Nh1, Nh1, int(Nh1 / 3)),\n",
    "                                      (Nh2, Nh2, int(Nh2 / 3)), \n",
    "                                      (Nh3, Nh3, int(Nh3 / 3))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassMLPgrid(xTrain, xTest, yTrain, yTest, paramSpace, maxIts, crossValids):\n",
    "    # Define the MLPClassifier.\n",
    "    mlp = MLPClassifier(max_iter = maxIts, random_state = 42)\n",
    "\n",
    "    print(\"Data normalizing.\")\n",
    "    scaler = StandardScaler()\n",
    "    xTrain = scaler.fit_transform(xTrain)\n",
    "    xTest = scaler.transform(xTest)\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    print(\"Grid search hyperparameter optimization.\")\n",
    "    grid_search = GridSearchCV(estimator = mlp, param_grid = paramSpace, cv = crossValids, n_jobs = -1)\n",
    "    grid_search.fit(xTrain, yTrain)\n",
    "\n",
    "    # Best parameters found during grid search.\n",
    "    print(\"Best hyperparameters found.\")\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train MLPRegressor with best parameters.\n",
    "    print(\"Training optimized model.\")\n",
    "    best_mlp = MLPClassifier(max_iter = maxIts, **best_params)\n",
    "    best_mlp.fit(xTrain, yTrain)\n",
    "\n",
    "    print(\"Finished model.\")\n",
    "    pre = best_mlp.predict(xTest)\n",
    "    acc = accuracy_score(yTest, pre)\n",
    "\n",
    "    return best_mlp, best_params, acc, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ClassMLPgrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bestMLP, bestParams, acc, pre \u001b[38;5;241m=\u001b[39m \u001b[43mClassMLPgrid\u001b[49m(xTrain, xTest, yTrain, yTest,hParamGrid, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(acc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ClassMLPgrid' is not defined"
     ]
    }
   ],
   "source": [
    "bestMLP, bestParams, acc, pre = ClassMLPgrid(xTrain, xTest, yTrain, yTest,hParamGrid, 20, 5)\n",
    "\n",
    "print('Accuracy:')\n",
    "print(acc)\n",
    "print()\n",
    "print(f'Best hyperparameters: {bestParams}')\n",
    "print()\n",
    "print('Clasification prediction:')\n",
    "for i in range(len(glacierForms)):\n",
    "    print(i, glacierForms[i], len(pre[np.where(pre == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer neuron range estimation: 106 and 176\n"
     ]
    }
   ],
   "source": [
    "NhMax = int(hiddenLayerSize(No, np.shape(xTrain)[1], np.shape(xTrain)[0], 6))\n",
    "NhMin = int(hiddenLayerSize(No, np.shape(xTrain)[1], np.shape(xTrain)[0], 10))\n",
    "print(f'Hidden layer neuron range estimation: {NhMin} and {NhMax}')\n",
    "\n",
    "hParamSpace = {'activation': ['relu', 'tanh'],\n",
    "               'alpha': uniform(0.001, 0.1),\n",
    "               'solver': ['adam', 'sgd'],\n",
    "               'early_stopping': [True],\n",
    "               'learning_rate': ['constant', 'adaptive'],\n",
    "               'hidden_layer_sizes': [(randint(NhMin, NhMax).rvs(),\n",
    "                                       randint(NhMin, NhMax).rvs(), \n",
    "                                       int(0.3 * randint(NhMin, NhMax).rvs()))]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassMLPran(xTrain, xTest, yTrain, yTest, paramSpace, maxIts, crossValids):\n",
    "    # Define the MLPClassifier.\n",
    "    mlp = MLPClassifier(max_iter = maxIts, random_state = 42)\n",
    "\n",
    "    print(\"Data normalizing.\")\n",
    "    scaler = StandardScaler()\n",
    "    xTrain = scaler.fit_transform(xTrain)\n",
    "    xTest = scaler.transform(xTest)\n",
    "    \n",
    "    # Perform GridSearchCV\n",
    "    print(\"Distribution search hyperparameter optimization.\")\n",
    "    grid_search = RandomizedSearchCV(estimator = mlp, param_distributions = paramSpace, cv = crossValids, n_jobs = -1)\n",
    "    grid_search.fit(xTrain, yTrain)\n",
    "\n",
    "    # Best parameters found during grid search.\n",
    "    print(\"Best hyperparameters found.\")\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train MLPRegressor with best parameters.\n",
    "    print(\"Training optimized model.\")\n",
    "    best_mlp = MLPClassifier(max_iter = maxIts, **best_params, random_state = 42)\n",
    "    best_mlp.fit(xTrain, yTrain)\n",
    "\n",
    "    print(\"Finished model.\")\n",
    "    pre = best_mlp.predict(xTest)\n",
    "    acc = accuracy_score(yTest, pre)\n",
    "\n",
    "    return best_mlp, best_params, acc, pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalizing.\n",
      "Distribution search hyperparameter optimization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45424\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found.\n",
      "Training optimized model.\n",
      "Finished model.\n",
      "Accuracy:\n",
      "0.9884553558380827\n",
      "\n",
      "Best hyperparameters: {'activation': 'tanh', 'alpha': 0.007990248655920507, 'early_stopping': True, 'hidden_layer_sizes': (115, 143, 26), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "\n",
      "Clasification prediction:\n",
      "0 Glacier 5002\n",
      "1 Ice cap 1841\n",
      "2 Perennial snowfield 0\n",
      "3 Seasonal snow-field 0\n",
      "4 Not assigned 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45424\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bestMLP, bestParams, acc, pre = ClassMLPran(xTrain, xTest, yTrain, yTest, hParamSpace, 20, 5)\n",
    "\n",
    "print('Accuracy:')\n",
    "print(acc)\n",
    "print()\n",
    "print(f'Best hyperparameters: {bestParams}')\n",
    "print()\n",
    "print('Clasification prediction:')\n",
    "for i in range(len(glacierForms)):\n",
    "    print(i, glacierForms[i], len(pre[np.where(pre == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
